---
title: 查找(Search)
date: 2024-04-29 17:35:33
permalink: /pages/275b75/
categories:
  - 数据结构
tags:
  - 
author: 
  name: Cyan
  link: https://github.com/willpast
---
## 【知识框架】
![图片描述](https://cdn.jsdelivr.net/gh/willpast/image/blog/ds_algo/ka-search.png)  
## 查找概论

### 一、查找的基本概念

**查找(Searching)** ：就是根据给定的某个值，在**查找表** 中确定一个其**关键字** 等于给定值的数据元素( 或记录)。

**查找表(Search Table)** ：是由同一类型的数据元素(或记录)构成的集合。

**关键字(Key)**：数据元素中唯一标识该元素的某个数据项的值，使用基于关键字的查找，查找结果应该是唯一的。例如，在由一个学生元素构成的数据集合中，学生元素中“学号”这一数据项的值唯一地标识一名学生。

**静态查找表(Static Search Table)** ：只作查找操作的查找表。

  * 主要操作

  1. 查询某个“特定的”数据元素是否在查找表中。
  2. 检索某个“特定的”数据元素和各种属性。

**动态查找表(Dynamic Search Table)** ： 在查找过程中同时插入查找表中不存在的数据元素，或者从查找表中删除已经存在的某个数据元素。

  * 主要操作

  1. 查找时插入不存在的数据元素。
  2. 查找时删除已存在的数据元素。

**平均查找长度** ：在查找过程中，一次查找的长度是指需要比较的关键字次数，而平均查找长度，则是所有查找过程中进行关键字的比较次数的平均值，其数学定义为：$ASL=\displaystyle\sum_{i=1}^{n}$ $P_iC_i$

​式中，$n$是查找表的长度；$P_i$是查找第i个数据元素的概率，一般认为每个数据元素的查找概率相等，即$P_i$​=$1/n$；$C_i$​是找到第i个数据元素所需进行的比较次数。平均查找长度是衡量查找算法效率的最主要的指标。  

## 顺序表查找

### 一、定义

顺序查找(Sequential Search)
又叫线性查找，是最基本的查找技术，作为一种最直观的查找方法，其基本思想是从线性表的一端开始，逐个检查关键字是否满足给定的条件。若查找到某个元素的关键字满足给定条件，则查找成功，返回该元素在线性表中的位置；若已经查找到表的另一端，但还没有查找到符合给定条件的元素，则返回查找失败的信息。

### 二、算法

下面给出其算法：
```c
/*有哨兵顺序查找*/
int Sequential_Search(int *a, int n, int key){
  int i;
  a[0] = key; //设置a[0]为关键字，称之为“哨兵”
  i = n;  //循环从数组尾部开始
  while(a[i] != key){
    i--;
  }
  return i; //返回0则说明查找失败
}

```

这种在查找方向的尽头放置“哨兵”免去了在查找过程中每一次比较后都要判断查找位置是否越界的小技巧，看似与原先差别不大，但在总数据较多时，效率提高很大，是非常好的编码技巧。  
上述顺序表查找时间复杂度是O(n)。

* * *

## 有序表查找

### 一、折半查找

折半查找(Binary
Search)技术，又称为二分查找。它的前提是线性表中的记录必须是关键码有序(通常从小到大有序)，线性表必须采用顺序存储。折半查找的基本思想是：在有序表中，取中间记录作为比较对象，若给定值与中间记录的关键字相等，则查找成功；若给定值小于中间记录的关键字，则在中间记录的左半区继续查找；若给定值大于中间记录的关键字，则在中间记录的右半区继续查找。不断重复上述过程，直到查找成功，或所有查找区域无记录，查找失败为止。

算法如下：
```c
int Binary_Search(SeqList L, ElemType key){
  int low = 0, high = L.length - 1, mid;
  while(low <= high){
    mid = (low + hight)/2;  //取中间位置
    if(L.elem[mid] == key){
      return mid; //查找成功返回所在位置
    }else if(L.elem[mid] > key){
      high = mid - 1; //从前半部分继续查找
    }else{
      low = mid + 1;  //从后半部分继续查找
    }
  }
  return -1;  //查找失败，返回-1
}

```

折半查找的过程可用二叉树来描述，称为判定树。  
我们知道，具有n个结点的二叉树的深度为$log2^{n+1}$，所以，折半查找的时间复杂度为$O(log2^n)$，平均情况下比顺序查找的效率高。  
因为折半查找需要方便地定位查找区域，所以它要求线性表必须具有随机存取的特性。因此，该查找法仅适合于顺序存储结构，不适合于链式存储结构，且要求元素按关键字有序排列。

### 二、插值查找

现在我们的新问题是，为什么一定要折半，而不是折四分之一或者折更多呢?  
比如要在取值范围0 ~ 10000之间100个元素从小到大均匀分布的数组中查找5，我们自然会考虑从数组下标较小的开始查找。  
所以，折半查找还是有改善空间的。  
上述折半查找代码的第4行，等式变换后可得到：  

**mid=(low+high)/2=low+(high−low)/2** 

也就是mid等于最低下标low加上最高下标high与low的差的一半。大佬们考虑的就是将这个1/2进行改进，改进为下面的计算方案：  

**mid=low+(high−low){(key−a[low])/(a[high]−a[low])}**

也就是说，我们把上述折半查找代码的第4行的代码改为： 
```c
mid = low+(key-L.elem[low])/(L.elem[high] - L.elem[low]) * (high-low);  //插值
```

就得到了另一种有序表查找算法，插值查找法。插值查找(Interpolation Search)
是根据要查找的关键字key与查找表中最大最小记录的关键字比较后的查找方法，其核心就在于插值的计算公式。应该说，从时间复杂度来看，它也是O(log2^​n)，但对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好得多。反之，数组中如果分布类似0,1,2,2000,2001,......,999998,99999这种极端不均匀的数据，用插值查找未必是很合适的选择。

### 三、斐波那契查找

斐波那契查找(Fibonacci Search)，它是利用了黄金分割原理来实现的。

[关于斐波那契数列，不了解的可点击这里做一个大致的了解](https://blog.csdn.net/Real_Fool_/article/details/113852222#2_236)

我们先定义一个斐波那契数组F：  
![图片描述](https://cdn.jsdelivr.net/gh/willpast/image/blog/ds_algo/search1.png)  
算法实现如下：
```c
/*斐波那契查找*/
int Fibonacci_Search(int *a, int n, int key){
  int low, high, mid, i, k;
  low = 0;  //定义最低下标为记录首位
  high = n; //定义最高下标为记录末尾
  k = 0;
  while(n > F[k] - 1){
    //计算n位于斐波那契数列的位置
    k++;
  }
  for(i=n; i<F[k]; i++){
    //在尾部补上F[k]-n-1个数，大小等于尾部最大值，否则会存在数组溢出
    a[i]=a[n];
  }
  while(low <= hight){
    mid = low + F[k-1]-1; //计算当前分隔的下标
    if(key < a[mid]){
      //若查找记录小于当前分隔记录
      hight = mid - 1;  //最高下标调整到分隔下标mid-1处
      k = k - 1;  //斐波那契数列下标减一位
    }else if(key > a[mid]){
      //若查找记录大于当前分隔记录
      low = mid + 1;  //最低下标调整到分隔下标mid+1处
      k = k - 2;  //斐波那契数列下标减两位
    }else{
      if(mid <= n){
        return mid; //若相等则说明mid即为查找的位置
      }else{
        return n; //若mid>n说明是补全数值，返回n
      }
    }
  }
  return -1;
}

```

斐波那契查找算法的核心在于:

  1. 当key=a[mid]时，查找就成功；
  2. 当key<a[mid]时，新范围是第low个到第mid-1个，此时范围个数为F[k-1]-1个；
  3. 当key>a[mid]时，新范围是第m+1个到第high个，此时范围个数为F[k-2]-1个。
  
![图片描述](https://cdn.jsdelivr.net/gh/willpast/image/blog/ds_algo/search2.png)  

也就是说，如果要查找的记录在右侧，则左侧的数据都不用再判断了，不断反复进行下去，对处于当中的大部分数据，其工作效率要高一些，而且斐波那契查找只是最简单加减法运算，所以尽管斐波那契查找的时间复杂也为O(logn)，但就平均性能来说，斐波那契查找要优于折半查找。不过如果是最坏情况，比如这里key=1，那么始终都处于左侧长半区在查找，则查找效率要低于折半查找。

## 线性索引查找

现实生活中计算机要处理的数据量是极其庞大的，而数据结构的最终目的是提高数据的处理速度，**索引**
是为了加快查找速度而设计的一种数据结构。索引就是把一个关键字与它对应的记录相关联的过程，
一个索引由若干个索引项构成，每个索引项至少应包含关键字和其对应的记录在存储器中的位置等信息。索引技术是组织大型数据库以及磁盘文件的一种重要技术。  
索引按照结构可以分为**线性索引、树形索引和多级索引** 。  
这里主要介绍线性索引，所谓线性索引就是将索引项集合组织为线性结构，也称为**索引表** 。我们重点介绍三种线性索引：**稠密索引、分块索引和倒排索引** 。

### 一、稠密索引

稠密索引是很简单直白的一种索引结构。  
**稠密索引是指在线性索引中，将数据集中的每个记录对应一个索引项，而索引项一定是按照关键码有序的排列** 。如下图所示：  
![图片描述](https://cdn.jsdelivr.net/gh/willpast/image/blog/ds_algo/search3.png)    
索引项有序也就意味着，我们要查找关键字时，可以用到折半、插值、斐波那契等有序查找算法，提高了效率。这是稠密索引优点，但是如果数据集非常大，比如上亿，那也就意味着索引也得同样的数据集长度规模，对于内存有限的计算机来说，可能就需要反复去访问磁盘，查找性能反而大大下降了。

### 二、分块索引

稠密索引因为索引项与数据集的记录个数相同，所以空间代价很大。为了减少索引项的个数，我们可以对数据集进行分块，使其分块有序，然后再对每一块建立一个索引项，从而减少索引项的个数。

分块有序，是把数据集的记录分成了若千块，并且这些块需要满足两个条件：

  * **块内无序** ：即每一块内的记录不要求有序。
  * **块间有序** ：例如，要求第二块所有记录的关键字均要大于第一块中所有记录的关键字，第三块的所有记录的关键字均要大于第二块的所有记录关键字…因为只有块间有序，才有可能在查找时带来效率。

对于分块有序的数据集，将每块对应一个索引项， 这种索引方法叫做分块索引。如下图所示，我们定义的分块索引的索引项结构分三个数据项：

  * **最大关键码** ：它存储每一块中的最大关键字，这样的好处就是可以使得在它之后的下一块中的最小关键字也能比这一块最大的关键字要大；
  * **块长** ：存储了块中的记录个数，以便于循环时使用；
  * **块首指针** ：用于指向块首数据元素的指针，便于开始对这一块中记录进行遍历。  
![图片描述](https://cdn.jsdelivr.net/gh/willpast/image/blog/ds_algo/search4.png)  


在分块索引表中查找，就是分两步进行:

  1. 在分块索引表中查找要查关键字所在的块。由于分块索引表是块间有序的，因此很容易利用折半、插值等算法得到结果。例如，在上图的数据集中查找62，我们可以很快可以从左上角的索引表中由57<62<96得到62在第三个块中。
  2. 根据块首指针找到相应的块，并在块中顺序查找关键码。

我们来分析一下它的平均查找长度：  
分块查找的平均查找长度为索引查找和块内查找的平均长度之和。设索引查找和块内查找的  
平均查找长度分别为LI​,LS​，则分块查找的平均查找长度为：$ALS=L_I$​ + $L_S$
我们假设，将长度为n的查找表均匀地分为b块，每块有s个记录，即b=n/s，在等概率情况下，若在块内和索引表中均采用顺序查找，则平均查找长度为：$ASL=L_I$​+$L_S$​=$(b+1)/2+(s+1)/2=(s2+2s+n)/2s$ 
此时，若 $s=\sqrt n$ ​，则平均查找长度取最小值$\sqrt n+1$；若对索引表采用折半查找时，则平均查找长度为：$ASL=L_I$​+$L_S$=⌈$log2^{b+1}$⌉+$(s+1)/2$

### 三、倒排索引

搜索引擎中涉及很多搜索技术，这里介绍一种最简单，也是最基础的搜索技术：**倒排索引** 。

我们举个简单的例子：  
假如下面两篇极短的文章。

  1. Books and friends should be few but good.
  2. A good book is a good friend.

忽略字母大小写，我们统计出每个单词出现在哪篇文章之中：文章1、文章2、文章(1，2)，得到下面这个表，并对单词做了排序：  
![图片描述](https://cdn.jsdelivr.net/gh/willpast/image/blog/ds_algo/search5.png)  
有了这样一张单词表，我们要搜索文章，就非常方便了。如果你在搜索框中填写“book"关键字。系统就先在这张单词表中有序查找“book"，找到后将它对应的文章编号1和2的文章地址返回。

在这里这张单词表就是索引表，索引项的通用结构是：

  * **次关键码** ，例如上面的“英文单词”；
  * **记录号表** ，例如上面的“文章编号"。

**其中记录号表存储具有相同次关键字的所有记录的记录号(可以是指向记录的指针或者是该记录的主关键字)。这样的索引方法就是倒排索引(invertedindex)。**

这名字为什么要叫做“倒排索引”呢？  
顾名思义，倒排索引源于实际应用中需要根据属性(或字段、次关键码)的值来查找记录（或主关键编码）。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。**由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引。**

当然，现实中的搜索技术是非常复杂的，要考虑诸多因素用到诸多技术，由于本文的侧重点并非搜索引擎，所以于此不再赘述。

## 二叉查找树与平衡二叉树
### 一、二叉查找树
参考：[二叉查找树](/pages/c052c6/#_2-4-二叉查找树)
### 二、平衡二叉树
参考：[平衡二叉树](/pages/c052c6/#_2-5-平衡二叉树)

## 多路查找树
参考：[多路查找树](/pages/c052c6/#_3-2-1-多路查找树的定义)
### 一、B树
参考：[B树](/pages/c052c6/#_3-3-b树)
### 二、B+树
参考：[B+树](/pages/c052c6/#_3-4-b-树)

## 散列表查找（哈希表）

### 一、散列表查找的基本概念

**散列表** 是根据关键字而直接进行访问的数据结构。也就是说，散列表建立了关键字和存储地址之间的一种直接映射关系。我们只需要通过某个函数f，使得 **存储位置=f(关键字)** 那样我们可以通过查找关键字不需要比较就可获得需要的记录的存储位置。

**散列技术** 既是一种存储方法，
也是一种查找方法，散列技术是在记录的存储位置和它的关键字之间建立一个确定的对应关系f，使得每个关键字key对应一个存储位置f(key)。查找时，根据这个确定的对应关系找到置上。  
这里我们把这种对应关系f称为**散列函数** ，又称为**哈希(Hash) 函数**。按这个思想，采用散列技术将记录存储在一块连续的存储空间中，这块连续存储空间称为**散列表** 或**哈希表(Hash table)**
。那么关键字对应的记录存储位置我们称为**散列地址** 。

散列函数可能会把两个或两个以上的不同关键字映射到同一地址，称这种情况为**冲突** ，这些发生碰撞的不同关键字称为**同义词**。一方面，设计得好的散列函数应尽量减少这样的冲突；另一方面，由于这样的冲突总是不可避免的，所以还要设计好处理冲突的方法。

理想情况下，对散列表进行查找的时间复杂度为O(1)，即与表中元素的个数无关。

### 二、散列函数的构造方法

在构造散列函数时，必须注意以下几点：

  1. 散列函数的定义域必须包含全部需要存储的关键字，而值域的范围则依赖于散列表的大小或地址范围。
  2. 散列函数计算出来的地址应该能等概率、均匀地分布在整个地址空间中，从而减少冲突的发生。
  3. 散列函数应尽量简单，能够在较短的时间内计算出任一关键字对应的散列地址。

下面介绍常用的散列函数。

#### 1、直接定址法

直接取关键字的某个线性函数值为散列地址，散列函数为**H(key)=key或H(key)=a∗key+b**，a和b是常数。这种方法计算最简单，且不会产生冲突。它适合关键字的分布基本连续的情况，若关键字分布不连续，空位较多，则会造成存储空间的浪费。  
举例：0~100岁的人口数字统计表，可以把年龄数值直接当做散列地址。

#### 2、数字分析法

例如当手机号码为关键字时，其11位数字是有规则的，此时是无需把11位数值全部当做散列地址，这时我们给关键词抽取，
抽取方法是使用关键字的一部分来计算散列存储位置的方法，这在散列函数中是常常用到的手段。  
数字分析法通常适合处理关键字位数比较大的情况，如果事先知道关键字的分布且关键字的若干位分布较均匀，就可以考虑用这个方法。这种方法适合于已知的关键字集合，若更换了关键字，则需要重新构造新的散列函数。

#### 3、平方取中法

这个方法计算很简单，假设关键字是1234，那么它的平方就是1522756，再抽取中间的3位就是227，用做散列地址。再比如关键字是4321，那么它的平方就是18671041，抽取中间的3位就可以是671，也可以是710，用做散列地址。平方取中法比较适合于不知道关键字的分布，而位数又不是很大的情况。

#### 4、除留余数法

这是一种最简单、最常用的方法，假定散列表表长为m，取一个不大于m但最接近或等于m的质数p，利用以下公式把关键字转换成散列地址。散列函数为**H(key)=key%p (p<=m)**

事实上，这方法不仅可以对关键字直接取模，也可在折叠、平方取中后再取模。  
除留余数法的关键是选好p，使得每个关键字通过该函数转换后等概率地映射到散列空间上的任一地址，从而尽可能减少冲突的可能性。

#### 5、随机数法

选择一个随机数，取关键字的随机函数值为它的散列地址。也就是**H(key)=random(key)**

这里random是随机函数。当关键字的长度不等时，采用这个方法构造散列函数是比较合适的。

### 三、处理散列冲突

任何设计出来的散列函数都不可能绝对地避免冲突。为此，必须考虑在发生冲突时应该如何处理，即为产生冲突的关键字寻找下一个“空”的Hash地址。

用$H_i$​表示处理冲突中第i次探测得到的散列地址，假设得到的另一个散列地址$H_i$​仍然发生冲突，只得继续求下一个地址$H_2$​，以此类推，直到$H_k$​不发生冲突为止，则$H_k$​为关键字在表中的地址。

#### 1、开放定址法

**所谓的开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址** ，只要散列表足够大，空的散列地址总能找到，并将记录存入。  
它的公式是：Hi​(key)=(f(key)+di​)%m (di​=1,2,3,...,m−1)式中，H(key)为散列函数；i=0,1,2,...,k (k<=m−1)；m表示散列列表表长；di​为增量序列。

取定某一增量序列后，对应的处理方法就是确定的。通常有以下4种取法：

  1. **线性探测法** 。当$di​=0,1,2,...,m−1$时，称为线性探测法。这种方法的特点是:冲突发生时，顺序查看表中下一个单元(探测到表尾地址m−1时，下一个探测地址是表首地址0)，直到找出一个空闲单元(当表未填满时一定能找到一个空闲单元)或查遍全表。  
  线性探测法可能使第i个散列地址的同义词存入第i+1个散列地址，这样本应存入第i+1个散列地址的元素就争夺第i+2个散列地址的元素的地址，从而造成大量元素在相邻的散列地址上堆积，大大降低了查找效率。

  2. **平方探测法** 。当$di=0^2,1^2,-1^2,2^2,-2^2,..,k^2, -k^2$时，称为平方探测法，其k < m/2，散列表长度m必须是一个可以表示成4k+3的素数，又称**二次探测法** 。  
  平方探测法是一种较好的处理冲突的方法，可以避免出现“堆积”问题，它的缺点是不能探测到散列表上的所有单元，但至少能探测到一半单元。

  3. **再散列法** 。当di​=Hash2​(key)时，称为**再散列法** ，又称**双散列法** 。需要使用两个散列函数，当通过第一个散列函数H(key)得到的地址发生冲突时，则利用第二个散列函数Hash2​(key)计算该关键字的地址增量。它的具体散列函数形式如下：**Hi​=(H(key)+i∗Hash2​(key))%m**  
  初始探测位置H0​=H(key)。 i是冲突的次数，初始为0。在再散列法中，最多经过m−1次探测就会遍历表中所有位置，回到H0​位置。
  4. **伪随机序列法** 。当di​=伪随机数序列时，称为伪随机序列法。

>
> 注意:在开放定址的情形下，不能随便物理删除表中的已有元素，因为若删除元素，则会截断其他具有相同散列地址的元素的查找地址。因此，要删除一个元素时，可给它做一个删除标记，进行逻辑删除。但这样做的副作用是：执行多次删除后，表面上看起来散列表很满，实际上有许多位置未利用，因此需要定期维护散列表，要把删除标记的元素物理删除。

#### 2、链地址法（拉链法）

**不换地方。**  
转换一下思路，为什么非得有冲突就要换地方呢，如果不换地方该怎么处理？于是我们就有了链地址法。

将所有关键字为同义词的记录存储在一个单链表中，我们称这种表为同义词子表，在散列表中只存储所有同义词子表的头指针。

例如，关键字序列为{12,67,56,16,25,37,22,29,15,47,48,34}，我们用除留余数法构造散列函数**H(key)=key%12**，用拉链法处理冲突，建立的表如下图所示。  
![图片描述](https://cdn.jsdelivr.net/gh/willpast/image/blog/ds_algo/search6.png)  

#### 3、公共溢出区法

这个方法其实就更加好理解，就是把凡是冲突的家伙额外找个公共场所待着。我们**为所有冲突的关键字建立了一个公共的溢出区来存放** 。

就前面的例子而言，我们共有三个关键字37,48,34与之前的关键字位置有冲突，那么就将它们存储到溢出表中，如下图所示。  
![图片描述](https://cdn.jsdelivr.net/gh/willpast/image/blog/ds_algo/search7.png)  
如果相对于基本表而言，有冲突的数据很少的情况下，公共溢出区的结构对查找性能来说还是非常高的。

### 四、散列表查找实现

#### 1、算法

首先是需要定义一个散列表的结构以及一些相关的常数。其中HashTable就是散列表结构。结构当中的elem为一个动态数组。
```c
#define SUCCESS 1;
#define UNSUCCESS 0;
#define HASHSIZE 12;  //定义散列表表长为数组的长度
#define NULLKEY -32768; //代表空地址
typedef struct{
  int *elem;  //数组元素存储基址，动态分配数组
  int count;  //当前数据元素个数
}HashTable;
int m=0;  //散列表表长，全局变量

```

有了结构的定义，我们可以对散列表进行初始化。
```c
/*初始化散列表*/
bool InitHashTable(HashTable *H){
  int i;
  m=HASHSIZE;
  H->count=m;
  H->elem=(int *)malloc(m*sizeof(int));
  for(i=0; i<m; i++){
    H->elem[i]=NULLKEY;
  }
  return TRUE;
}

```

为了插入时计算地址，我们需要定义散列函数，散列函数可以根据不同情况更改算法。
```c
/*散列函数*/
int Hash(int key){
  return key % m; //除留余数法
}

```

初始化完成后，我们可以对散列表进行插入操作。假设我们插入的关键字集合就是前面的{12,67,56,16,25,37,22,29,15,47,48,34}。
```c
/*插入关键字进散列表*/
void InsertHash(HashTable *H, int key){
  int addr = Hash(key); //通过散列函数求散列地址
  //如果不为空。则冲突
  while (H->elem[addr] != NULLKEY){
    addr = (addr + 1) % m;  //开放定址法的线性探测
  }
  H->elem[addr] = key;  //直到有空位后插入关键字
}

```
    

    

代码中插入关键字时，首先算出散列地址，如果当前地址不为空关键字，则说明有冲突。此时我们应用开放定址法的线性探测进行重新寻址，此处也可更改为链地址法等其他解决冲突的办法。

散列表存在后，我们在需要时就可以通过散列表查找要的记录。
```c
/*
散列表查找关键字
找到后用addr保存地址
*/
bool SerachHash(HashTable H, int key, int *addr){
  *addr = Hash(key);  //通过散列函数求得散列地址
  //如果不为空，则有同义词冲突
  while(H.elem[*addr] != key){
    *addr = (*addr+1) % m;  //开放地址法的线性探测
    if(H.elem[*addr] == NULLKEY || *addr == Hash(key)){
      //如果循环到空址或回到原点
      return FALSE; //则说明关键字不存在
    }
  }
  return TRUE;
}

```

查找的代码与插入的代码非常类似，只需做一个不存在关键字的判断而已。

#### 2、性能分析

从散列表的查找过程可见：

  1. 虽然散列表在关键字与记录的存储位置之间建立了直接映像，但由于“冲突”的产生，使得散列表的查找过程仍然是一个给定值和关键字进行比较的过程。因此，仍需要以平均查找长度作为衡量散列表的查找效率的度量。
  2. 散列表的查找效率取决于三个因素：散列函数、处理冲突的方法和装填因子。
  3. 若用ci​表示每一个关键字查找的次数，则平均查找次数可表示为：$ASL=(\displaystyle\sum_{i=0}^{m}c_i)/m$

**装填因子** 。散列表的装填因子一般记为α，定义为一个表的装满程度，即α=n(表中记录数)​/m(散列表长度)​散列表的平均查找长度依赖于散列表的装填因子α，而不直接依赖于n或m。直观地看，α越大，表示装填的记录越“满”，发生冲突的可能性越大，反之发生冲突的可能性越小。

不管记录个数n有多大，我们总可以选择一个合适的装填因子以便将平均查找长度限定在一个范围之内，此时我们散列查找的时间复杂度就真的是O(1)了。
为了做到这一点，通常我们都是将散列表的空间设置得比查找集合大，此时虽然是浪费了一定的空间，但换来的是查找效率的大大提升，总的来说，还是非常值得的。


## 参考文章

- [数据结构知识详细梳理](https://blog.csdn.net/Real_Fool_/article/details/115044709)