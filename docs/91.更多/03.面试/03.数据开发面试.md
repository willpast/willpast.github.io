---
title: 数据开发面试
date: 2024-06-19 21:06:38
permalink: /pages/612ae6/
categories:
  - 更多
  - 面试
tags:
  - 
author: 
  name: Cyan
  link: https://github.com/willpast
---
## 数据仓库|数据湖|数据中台
数据仓库(ODS|CDM|TDM|ADM)

**不成熟数仓**:具备部分数仓规范或存在多套规范约束,且在落地实施的过程中,未能严格落地实施,导致数据仓库建设比较混乱

    方法论:①识环境(组织|业务|技术)②找问题③理业务(业务流|数据流)④定框架(技术架构)⑤建标准(分层|数据域|规范)⑥落流程(建模|报表|测试)⑦强执行(计划|pm)⑧善总结(总结经验|反哺流程)

**模型设计原则**:高内聚低耦合|核心扩展模型分离|公共逻辑下沉|成本性能平衡|一致性|命名清晰可理解

**好的模型**:应该更好的组织、存储数据,以便在访问性能、数据成本、使用效率和数据质量之间找到最佳平衡点;稳定/通用/复用/易用.

**数仓优劣**:通过osm(Object-Strategy-Measure)指标体系来衡量.O:数仓优劣判断;S:数据监控、元数据管理、业务流程的理解、核心模型相对稳定、高内聚低耦合;M:核心度量指标如下

    生产指标:跨层引用率/表引用数/引用链路长度/表命名规范率/数据泄露率;使用指标:数据准时率/数据查阅数/数据用户数占比/数据授权用户数/自助取数平均耗时        

    金服指标:质量(故障数、IPH准点率、DQC达标率)、成本(存储和计算)、效率(开发人效、查询效率)、安全(敏感数据标注率)、体验(产品使用:手写查询率|高频产品使用率;查询体验:不良查询率)

    琅琊榜:数据的生命周期是从产生、加工、应用、消亡的过程,分为6个阶段:规范设计、模型建设、质量管理、数据应用、安全审计、资源维护
    
    琅琊榜指标:数据规范(建模:命名不规范;注释不完整;责任人缺失/流向:夸层依赖率;引用链路过长)、数据质量(准时:iph准点率/准确:dqc达标率)、应用体验(查询:平均查询时长/内容:ods层访问率)、计算资源(有效计算:失败任务率/计算效率:倾斜率;高耗时任务率)、存储资源(有效存储:无效存储率/存储效率:小文件率;生命周期管理率)    

**纵向主题域**:是把那些关联紧密但不同的数据主题,交汇融合到一个更大的主题域当中,也更容易被分析人员调取利用.分域方法:①业务过程②业务系统③业务部门④功能或应用⑤行业经验
    
    主题域:面向业务过程,将业务活动事件进行抽象的集合,如下单、支付、退款都是业务过程,针对公共明细层(DWD)进行主题划分.
    
    数据域:面向业务分析,将业务过程或者维度进行抽象的集合,针对公共汇总层(DWS)进行数据域划分.

**横向分层优点**:隔离原始数据(解耦)、复杂问题简单化、增加数据复用性、数据流向清晰(管理)   
    
    ODS贴源层:全域统一存储.保留原始业务流程数据,与业务系统基本保持一致,存放原始数据,不做处理
        .MT埋点:需求、配置、埋点、验证、上报、各业务分发处理;MY埋点:spm位置模型:a站点|b页面|c区块|d点位;scm内容模型:a投放平台|b内容分类|c内容id|d算法版本|e投放范围
    CDM数仓层:标准化的数据底座,又细分为DWD和DWS.它的主要作用是完成数据加工与整合、建立一致性的维度、构建可复用的面向分析和统计的明细事实表以及汇总公共粒度的指标
        .明细层DWD:业务过程建模(业务过程ID+维度+事实),主要对ODS层数据进行清洗、归因、规范化处理
        .汇总层DWS:分析主体建模(分析主体ID+维度+指标),构建公共粒度的汇总指标多维事实宽表
        .MT主题域:由传统teardate金融业务主题域(参与人|协议|事件|资源|营销|财务)向面向分析主题域(用户|商家|交易|营销|风控|流量)转换;①ods_view隔离业务数据脱敏②base清洗标准化③topic领域拆分,范式建模④mid_logic单实体|mid_topic_view多实体⑤mid维度加工⑥detail多维事实⑦summary
        .ant主题域:流量|设备|用户|营销|商家|数字化|产品;业务过程:①采集:唤起刷脸|刷脸授权|点击拍照按钮|图像采集②识别:提特征|活体|意愿判断|检索|风控|zid确定③确认:0411页面|识别结果④支付:标准|极速
    TDM标签层:面向对象建模,对跨业务板块、数据域的对象进行整合,通过ID-Mapping把各业务板块、业务过程中同一对象的数据打通,形成全域标签体系,方便分析挖掘 
        建设:确定对象(人|物|关系)、ID打通、标签设计(标签类目|标签和标签值)、标签表设计;标签搭建步骤:①还原业务流程②覆盖生命周期③明确商业目标④从策略推标签
        .标签体系:①CDP:基本信息、LBS、关系、行为、偏好、用户分级、金融属性、营销属性、风险属性②FUP:基础属性、用户分层、兴趣偏好设、用户行为、营销属性、风险属性
        .ant标签分类:事实类(基础标签一般具备可复用、可解释、可增长的特性)、刻画类(无行业特征,不随外界变化预测;usernet评测;基础信息|位置信息|人生阶段|职业信息|财富信息)、意图类(有行业特征,后续行为的预测;置信度衡量;购物偏好|刷脸意愿)
        .ant标签平台:目标是实现统一的标签自动生成、评估、推荐,提供智能化、自动化的标签生产及标签效果评估体系.四个一级生产工厂：①基于基础数据标签挖掘工厂②基于大模型实现sql自动生成标签工厂③基于图算法挖掘的标签自动扩散工厂④基于多模态数据标签挖掘工厂 
        .标签生产:①原子标签②衍生标签:由原子标签以表达式的形式组合③模型标签:按需求通过模型训练形成
        .标签框架:①基于营销触点的用户标签体系,先把用户分为不同的营销阶段,再细分每个阶段需要做的事情和标签②基于增长漏斗的AARRR模型③用户价值分层模型RFM④基于用户偏好的模型        
    ADM应用层:灵活支撑业务需求.面向业务的特殊需要加工业务特定数据,以满足业务及性能需求,向特定应用组装应用数据(多个维度组合+指标).   

**数仓层建设过程**(点线面体)以维度建模为基础,构建总线矩阵,划分业务板块,定义主题域、数据域、业务过程、维度、原子指标、修饰类型、派生指标,确定维度表、事实表的模型设计

**kimball维度模型**:按照事实表、维度表来构建数仓、集市,从分析决策的需求出发构建模型,为分析需求服务,重点关注如何快速地完成需求,且具有较好的大规模复杂查询性能;①选择业务过程②声明粒度③确认维度④确认事实

    分类:①高层模型,直接产出目标是创建高层维度模型图,它是对业务过程中的维表和事实表的图形描述.确定维表创建初始属性列表,为每个事实表创建提议度量②详细模型,填补高层模型缺失的信息,不断测试模型能否满足业务需求,确保模型的完备性.确定每个维表的属性和事实表的度量,确定信息来源的位置、定义,确定属性和度量填入模型的初步业务规则
    
    特点:自上而下,业务驱动.这种方式建设周期短,用户能很快看到结果,简单易理解、性能好、可扩展性好;缺点是数据冗余,不能保证数据来源的一致性和准确性

**inmon范式模型**:①领域(主题域)建模,主要是针对业务模型进行抽象处理,生成领域(主题域)概念模型②逻辑建模,是将领域模型的概念实体以实体之间的关系进行数据库层次的逻辑化③物理建模

    分类:①ERD(EntityRelationshipDiagram)层,描述业务的实体或主题域以及它们之间的关系②DIS(DataItemSet)层,描述数据模型中的关键字、属性以及细节数据之间的关系③物理层,描述数据模型的物理特性
    
    特点:自下而上,数据驱动.从整个企业的环境入手,建立数据仓库,要做很全面的设计,减少数据冗余,占用存储空间少,方便解耦;缺点是开发周期比较长,维护成本高

    1NF:每个属性值唯一,不具有多义性.要求属性具有原子性,即列不可再分解;2NF:每个非主属性必须完全依赖于整个主键,而非主键的一部分.要求记录有惟一标识,即不存在部分依赖;3NF:每个非主属性不能依赖于其他关系中的属性,要求字段没有冗余,即不存在传递依赖

**模型**:①星型模式是以事实表为中心,所有的维度表连接在事实表上,像星星一样②雪花模式是对星形模式的扩展,某些维表被规范化,进一步分解到维表中③星座模式是星型模式延伸而来,星型模式是基于一张事实表的,而星座模式是基于多张事实表的,共享维度信息④宽表模型:是基于维度模型的扩展,采用退化维度的方式,将不同维度的度量放入数据表的不同的列中,它更易于理解,易扩展

**数据中台|数仓区别**:数仓是支持管理决策和业务分析,数据中台则是将数据服务化后提供给业务系统;数据中台不断地将数据进行资产化、价值化并应用到业务,是一套把数据变成资产并服务业务的机制

**数据湖**本质上是一个中心化的、一体化的存储技术,并且追求技术架构的统一化(如流批一体,服务分析一体化).特点:保真性、灵活性、可管理、可追溯、丰富的计算引擎、多模态存储引擎

**湖仓一体**:直接在用于数据湖的低成本存储上实现与数据仓库中类似的数据结构和数据管理功能.避免传统的数据湖、数据仓库之间的数据移动,将原始数据、加工清洗数据、模型化数据，共同存储于一体化的“湖仓”中，既能面向业务实现高并发、精准化、高性能的历史数据、实时数据的查询服务，又能承载分析报表、批处理、数据挖掘等分析型业务

**流批一体**:平台层(dp)|api层(table|datastream)|算子层(source|sink connector、unified operator)|插拔组件层(Shuffle组件|调度组件)|资源管理层(k8s);mix表引入了虚拟列和流批标识的能力,在其中一方字段缺失的情况,或者字段的逻辑不是完全一致的情况,通过流批标识,可在代码中显示判断并进行逻辑处理

**HSAP**:将简单点查称为数据服务,将复杂查询称为分析,而两者的混合负载就称为HSAP,有4部分:Batch|Analytical交互式分析|Servering高QPS的在线服务|transaction
## 数据管理
**数据管理**:宏观定目标、中观找方案、微观重任务拆解.数据管理和数据治理的区别,数据管理的整体驱动力是确保组织可以从其数据中获得价值,是总体战略的层面;数据治理聚焦于如何制定有关数据的决策,以及人员和流程在数据方面的行为方式,更多是细节执行层面.数据治理保障数据被管理到,数据管理数据达到既定目标.

**治理步骤**:准备:①找症状定目标②理数据看现状③定规则做评估;开展:④看结果找原因⑤抓重点分阶段⑥定路线做计划⑦找核心做保障;保障:⑧管进度保治理⑨做评估搭监控;

    事前控(分析|约束|诊断)|事中管(监控|告警)|事后治(治理|评估|方法论|工具化);
    
    监控体系:指标监控|度量体系:健康分
    
    评估体系:评估报告.如账单,红黑榜
    
**事故处理**:①预防阶段:降低故障率,如开发规范,架构优化②发现阶段:提升监控率,如指标监控、全流程监控③处理阶段:提升处理率,降级策略、优化流程④总结阶段:降低重复率,多做复盘

**ETL评分专利**:新鲜度+复杂度+成本度(0.25计算成本、0.25存储成本、0.5执行时长)+依赖度+查询度        

**ant操作**:一套组织体系(组织建设|制度保障)、一套治理方法论(稳定|质量|规范|安全|成本)、一个平台工具支撑&运营(数据研发平台|监控告警平台|数据质量平台)

**ant核心步骤**:①成立治理组织②平台能力建设,事前:通过数据研发平台融合治理流程,包含架构约束、项目管控、发布管控;事中:监控告警平台,dqc、基线、实时告警、实时拦截;事后:数据治理平台,治理数字运营,治理画像、成本账单、红黑榜、健康分③技术升级:存储,模型优化分级存储和裁剪,优化回收站,提供存储利用率;计算:一读多写,减少读数据资源消耗;临时表占比超5成,缩短表生命周期设置,自动清理垃圾表

    平台能力建设:通过基础元数据,沉淀治理数字画像,驱动识别引擎、风险处置、数据管控的能力建设,打造治理融于流程、治理数字运营的平台,在事前、事中、事后进行全方位,全生命周期的数据治理,产出可持续管控的精品资产,同时保障数据不出事、管得住、信得过  

**ant案例**:复兴之战,进行设备促活和挽回 发货|激活|开机|活跃|维保|回收|报废;事前:分析评估,组织+流程+来源+埋点+链路;事中:监控告警、基线;事后:看板+复盘;   

**数据管理**:dama1定义是规划、控制和提供数据及信息资产的一组业务职能,包括开发、执行和监督有关数据的计划、政策、方案、项目、流程、方法和程序,从而控制、保护、交付和提高数据资产的价值.**目标**:实现数据资产化、发挥数据资产的价值.

**数据资产管理**:定义,紧紧围绕着把数据作为一种资产,基于数据资产的价值、成本、收益开展全生命周期的管理,以体系化的方式实现数据的可用、好用,充分释放数据价值;作用:①全面盘点数据资产②不断提升数据质量③是实现数据互联互通④提高数据获取效率⑤保障数据安全合规⑥数据价值持续释放

**数据治理**:①GB定义:数据资源及其应用过程中相关管控活动、绩效和 风险管理的集合②DAMA定义:对数据资产管理行使权力和控制的活动集合③何为数据治理,治为整治,关注数据质量,保障数据稳定性、准确性,合理控制数据的生命周期,降低成本.理为梳理和管理,数据的基本信息、状态、关联关系等,目标是搞清有哪些数据、从哪来到哪去,最终用到什么地方.数据治理是一个从混乱到有序的过程,以服务组织战略目标为基本原则,通过流程制度的制定,以及数据资产的梳理、采集清洗、结构化存储、可视化管理和多维度分析,提升数据资产价值、业务模式创新和经营风险控制的过程.它是涉及企业战略、组织架构、数据标准、管理规范、数据文化、技术工具的综合体.

    目标:根据策略和最佳实践来正确地管理数据,提升数据价值.狭义是确保数据的质量,可用性,安全性和易用性;广义是解决数据从采集加工/应用分析/销毁全生命周期内的口径、成本、安全、合规和产出问题,提升数据价值

    治理4个层面:道术法器.“器”服务于“术”,“术”符合于“法”,“法”根基于“道”,“道法术器”整个体系又在“势”的裹挟下不断演进并驱动“势”的前进和变化。        
        战略层面(道|方向):包括数据战略、组织机制、数据文化,重点在于指明哪些决策要制定,由谁来负责,数据战略是顶层的策略.
        管理层面(法|路径):包括理现状与定目标、数据治理能力成熟度评估、路线图规划、保障体系建设、技术体系建设、策略执行与监控等.强调数据治理的流程、制度和方法等
        执行层面(术|技术):包括建立数据治理各项技术能力,实现对各项数据资源的有效管理和控制,强调数据治理的具体操作和技术,如数据建模、元数据管理、主数据管理、数据质量管理、数据安全治理等
        工具层面(器|工具):提升数据治理的效能,工具层面强调对于技术和工具的使用.如主数据管理工具、元数据管理工具、数据质量管理工具、数据安全管理工具、数据交换共享工具等
    业务驱动:对业务目标的贡献;降低风险(风险管理|数据安全|数据隐私);优化流程(元数据管理|开发效率|质量提升)数据治理的价值评估,主要包括创造价值和节约成本,即降本增效; 

**dama2017**:数据管理协会知识体系.11职能:数据架构|数据模型与设计|数据存储与操作|数据安全|数据集成与互操作性|文本与内容管理|参考数据和主数据|数据仓库和商业智能|元数据|数据质量;7个因素:目标和原则|角色和职责|活动|工具|组织和文化|技术|交付成果

**dcmm2018**:数据管理能力成熟度评估.8过程域:组织(数据生存周期|数据战略);制度(数据治理|数据架构);流程(数据标准|数据质量);技术(数据安全|数据应用)

**dama治理4阶段**:①数据建模和设计|数据存储和运营|数据安全|数据集成和互操作:组织购买包含数据库功能的应用程序.这意味着组织以此作为数据建模和设计、数据存储和数据安全的起点.要使系统在其数据环境中运行,还需要做数据集成和交互操作方面的工作.②数据架构|元数据|数据质量:一旦他们开始使用应用程序,他们将发现数据质量方面的挑战.但获得更高质量的数据取决于可靠的元数据和一致的数据架构.它们说明了来自不同系统的数据是如何协同工作的.③数据治理|文档和内容管理|参考和主数据管理|数仓和BI:管理数据质量、元数据和架构需要严格地实践数据治理,为数据管理活动提供体系性支持.数据治理还支持战略计划的实施,如文档和内容管理、参考数据管理、主数据管理、数据仓库和商务智能,这些黄金金字塔中的高级应用都会得到充分地支持.④数据分析|数据挖掘:该组织充分利用了良好管理数据的好处,并提高了其分析能力.

**思考**:系统缺失业务约束,都是事后治理,结合金融和互联网的经验,需要从事后治理向事先管控转变,从被动治理向主动治理转变,从单纯的治理向治理+服务扩展,从理论向实战落地转变;

**业界**:二者是为了解决跨技术栈和平台的数据接入和分析问题,让数据还保留在原来的地方,而不是集中到一个平台或者领域.
    
    DataFabric是中心化,以技术为中心,通过技术和流程的改进,以智能化的主动元数据为核心来支撑复杂的数据治理,降低数据的管理和使用的难度,提高数据的价值;
    
    DataMesh是分而治之,聚集于方法论,将数据治理拆分到各业务领域,分别产出业务领域的数据产品,通过组织和治理的方式,让数据的所有权分散,更加贴近业务,提高数据的实际应用价值;
    
    两者都难实现原因:技术难度大、组织改变难、质量问题多;实现路径:高效的数据集成能力、精细的数据治理机制、强大的数据分析能力,将数据转化为有价值的信息和洞察;
## 大数据
**大数据**:分布式cap,Consistency一致性|Availability可用性|Partition tolerance分区容忍性

**olap**:数据量|性能|灵活性①MPP架构:数据量大和灵活性高,缺点:响应时间没保证,性能不稳定②预计算:牺牲灵活性换性能,秒级响应.缺点:不太灵活③搜索引擎:灵活性换性能,缺点:多表查询性能低

**Spark**:提交spark任务为一个app,根据任务里的action算子将app划分为多个job,每个job按照宽依赖划分为多个stage,每个stage按照处理数据不同划分为不同task,运行在executor中;stage的task的数量是输入文件的切片个数来决定的;job任务的task数量是stage数量乘以task数量的总和;stage中task并行度就是executor拥有的cores的数量
    
    窄依赖是父RDD的一个分区只会被子RDD的一个分区依赖,例如map,flatMap,还有filter,不涉及Shuffle操作;宽依赖是父RDD的一个分区会被子RDD的多个分区依赖,涉及Shuffle,例reduceBykey(shuffle前会combine)和groupByKey等.
    
    为什么要设计宽窄依赖:①窄依赖的多个分区可以并行计算②窄依赖的一个分区的数据如果丢失只需要重新计算对应的分区的数据③对于宽依赖,必须等到上一阶段计算完成才能计算下一阶段
    
    repartition一定会发生shuffle,coalesce根据传入的参数来判断是否发生shuffle;增大rdd的partition数量用
    repartition,会进行shuffle,减少时使用coalesce,不会进行shuffle
    
    cache:内存,不会截断血缘关系,使用计算过程中的数据缓存;checkpoint:磁盘,截断血缘关系,在ck之前必须没有任何任务提交才会生效,ck过程会额外提交一次任务
    
    优化:①对需要重复计算的rdd才使用cache,同时及时释放掉(unpersist)不再需要使用的RDD②避免使用shuffle运算③合理配置参数Executor/Task/core,合理分配持久化/shuffle的内存占比
    
    receiver模式:①在executor上会有receiver从kafka接收数据并存储在executor中,在到了batch时间后触发job去处理接收到的数据,1个receiver占用1个core②为了不丢数据需要开启WAL预写日志机制,会将receiver接收的数据备份到第三方系统上③receiver内部使用Kafka的高阶API去消费数据及自动更新offset,无法保证数据被处理一次且仅一次,可能会处理两次.因为Spark和zk之间可能是不同步的
    
    direct模式:①定期查询kafka中的每个partition的最新的offset,每个批次拉取上次处理的offset和当前查询的offset的范围的数据进行处理②为了不丢数据,无需将数据备份落地,而只需要手动保存offset③内部使用Kafka的低阶API去消费数据,需要手动维护offset,kafka zk上不会自动更新offset.一次且仅一次的事务机制

**flink**:四个基石Checkpoint|State|Time|Window(时间time/数据count);无重叠Tumbling(size=interval)|有重叠Sliding(size>interval)|丢失数据(size < interval)
    
    运行流程:Client接收用户CODE编译成StreamGraph,Clien侧优化成JobGraph(算子的Chain链等);流转到JobManager侧转换成ExcutionGraph,资源申请,启动TM,ExcutionGraph转换成物理执行计划,TM执行
    
    运行角色:①JobManager:集群中的管理者Master,它是整个集群的协调者,负责接收FlinkJob,协调检查点,Failover故障恢复等,同时管理集群中从节点TaskManager②TaskManager:负责执行计算的Worker,在其上执行FlinkJob的一组Task,每个TaskManager负责管理其所在节点上的资源信息,如内存、磁盘、网络,在启动的时候将资源的状态向JobManager汇报③Client:程序提交的客户端,Client会对Flink程序进行预处理,并提交到Flink集群中处理,所以Client需要从用户提交的Flink程序配置中获取JobManager的地址,并建立到JobManager的连接,将FlinkJob提交给JobManager
    
    容错:Flink实现容错主要靠CheckPoint机制和State机制.Checkpoint负责定时制作分布式快照、对程序中的状态进行备份;State用来存储计算过程中的中间状态

    Checkpoint:保证Flink集群在某个算子因为某些原因（如,异常退出）出现故障时,能够将整个应用流图的状态恢复到故障之前的某一状态,保证应用流图状态的一致性.每个需要Checkpoint的应用在启动时,Flink的JobManager会创建一个CheckpointCoordinator,它全权负责本应用的快照制作

    Watermark:处理EventTime窗口计算提出的一种机制,本质上是一种时间戳.如果只根据EventTime决定Window的运行,不能明确数据是否全部到位,但又不能无限期的等待,此时要有个机制来保证一个特定的时间后,必须触发Window进行计算,这个机制就是Watermark.Watermark是用于处理乱序事件的,通常用Watermark机制结合Window来实现,可以理解成一个延迟触发机制

    高延时任务处理:在后台任务管理中,可以看到哪个算子和task出现了反压.最主要的手段是资源调优和算子调优.资源调优是对作业中的Operator的并发数(parallelism)、CPU(core)、堆内存(heap_memory)等参数进行调优;作业参数调优包括并行度的设置,State的设置,checkpoint的设置

    反压处理:内部是基于producer-consumer模型来进行消息传递的,Flink的反压设计也是基于这个模型。使用了高效有界的分布式阻塞队列,就像Java阻塞队列,下游消费者消费变慢,上游就会受到阻塞

    window出现数据倾斜:指的是数据在不同的窗口内堆积的数据量相差过多.本质原因是数据源头发送的数据量速度不同导致的。通过两种方式解决:在数据进入窗口前做预聚合;重新设计窗口聚合的key

**MapReduce**:一种分布式编程模型,采用“分而治之”的思想,将一个大规模数据集分解为多个小规模数据,然后分发给集群中多个节点共同完成计算.可以降低运算复杂度,提高运算效率
    
    map数量=split数量=文件大小/Math.max(minSize, Math.min(maxSize, blockSize)),splitsize默认是128M,blockSize默认是256M

    reducer数量=min(hive.exec.reducers.max,总输入数据量/hive.exec.reducers.bytes.per.reducer),也可手动设置set mapred.reduce.tasks

    Shuffle:是map阶段产生数据输出到reduce阶段取得数据作为输入之前的一个过程;步骤:分区partition-环形缓冲器memoryBuffer-溢写spill(排序sort-[合并combiner])-归并merge-复制copy-归并merge

    Collect:将MapTask的结果输出到默认大小为100M的环形缓冲区,保存的是key|value序列化数据,保存前进行Partition分区信息

    Spill:当内存中的数据量达到一定的阀值,就会将数据溢写入本地磁盘,数据写入磁盘之前在内存中对数据进行快速排序的操作,若配置combiner,会将有相同分区号和key的数据排序

    MapTask阶段Merge:把所有溢出的临时文件进行一次归并排序操作,以确保一个MapTask最终只产生一个整体有序的中间数据文件

    Copy:ReduceTask通过RPC向JobTracker询问Map任务是否已经完成,若完成,则开始复制数据,启动Fetcher线程,通过http方式到已经完成MapTask的节点上复制数据,默认会保存在内存的缓冲区,当内存的缓冲区达到一定的阀值,会将数据写到磁盘

    ReduceTask阶段Merge:在ReduceTask远程复制数据时,会在后台开启两个线程(一个是内存到磁盘的合并,一个是磁盘到磁盘的合并)对内存到本地的数据文件进行归并排序操作

    Sort：在对数据进行合并时,会进行排序操作,由于MapTask已对数据进行了局部的排序,ReduceTask只需保证Copy的数据的最终整体有效性即可

    ExactlyOnce:Source端支持数据Replay,保证数据不丢失,Sink端支持幂等或事务.事务两种的实现方式:预写日志write-ahead-log,WAL和两阶段提交two-phase-commit,2PC
        WAL:①先把结果数据作为日志(log)状态保存起来②进行检查点保存时,也会将这些结果数据一并做持久化存储③在收到检查点完成的通知时,将所有结果一次性写入外部系统;如果检查点已经成功保存、数据也成功地写入到了外部系统,但最终保存确认信息时出现故障,Flink最终还是会认为没有成功写入.于是发生故障时,不会使用这个检查点,而需要回退到上一个,这样就会导致这批数据的重复写入
        
        2PC:①当第一条数据到来时或者收到检查点的分界线时,Sink任务都会启动一个事务②之后接收到的所有数据,都通过这个事务写入外部系统,这时由于事务没有提交,所以数据尽管写入了外部系统,但是不可用,是“预提交”的状态③当Sink任务收到JobManager发来检查点完成的通知时,正式提交事务,写入的结果可用了

        kafka:幂等+事务.幂等producer保证发送单个分区的消息只会发送一次,不会出现重复消息;事务保证原子性地写入到多个分区        
    
        flink:Flink和Kafka连接时,怎样保证端到端的exactly-once状态一致性:
            ①Flink内部:通过检查点机制保证状态和处理结果的exactly-once语义
            ②输入端:Kafka可以对数据进行持久化保存,并可以重置偏移量.在Source任务中将当前读取的偏移量保存为算子状态,写入到检查点中;当发生故障时,从检查点中读取恢复状态,并由连接器Consumer向Kafka重新提交偏移量,就可以重新消费数据、保证结果的一致性
            ③输出端:两阶段提交,写入Kafka的过程实际上是一个两段式的提交:处理结果,写入Kafka是基于事务的预提交;等到检查点保存完毕,才会提交事务进行正式提交.如果中间出现故障,事务进行回滚,预提交就会被放弃;恢复状态之后,也只能恢复所有已经确认提交的操作
    
**容错**:storm是RecordsACK机制;SparkStreaming是WAL及RDD血统机制;flink是基于Chandy-Lamport分布式快照checkpoint机制,确定当前流式计算所处的状态,包括处理记录和算子状态,然后生成该状态的一致性快照,并将快照存储在持久存储中.
    
**反压**:数据管道中某个节点成为瓶颈,处理速率小于上游发送数据的速率,需要对上游进行限速.
    strom:从源头降速.是通过zookeeper来决定的,当strom感受到处理不过来时,就会像zookeeper增加一个znode,然后strom发现了这个znode,对应的上游数据就会阻塞,不会发送数据

    spark:Receiver模式限制每个receiver每秒可以接受的数据;Direct模式来限制每个分区每次所能接受的最大记录数

    flink:逐级反压.通过webUI中BackPressure界面锁定反压算子(subTask的ratio(计算缓冲区阻塞线程数与总线程数的比值)为1和status为high),具体反压是由于当前Task自身处理速度慢还是由于下游Task处理慢导致的,需要通过metric监控判断,可能导致数据延迟或CheckPoint异常,会影响两项指标:checkpoint时长和state大小
        思路:①并行度优先级设置(算子层面>环境层面>客户端层面>系统层面)②Source并行度:数据源端是Kafka,设置为Kafka对应Topic的分区数③Transform并行度:Keyby之前的算子并行度可以和source保持一致,Keyby之后的算子如果并发较大,建议设置并行度为2的整数次幂,小并发任务的并行度则不一定需要设置成2的整数次幂④Sink端并行度:Sink端要与下游的服务进行交互,并行度还得根据下游的服务抗压能力来设置,如果Sink端的数据量小,并行度可以设置的小一些

        处理:Flink不需要一个特殊的机制来处理背压,因为Flink中的数据传输相当于已经提供了Credit-based应对背压的机制.只有从代码上与资源上去做一些调整①数据倾斜造成的反压,通过数据分组的key预聚合来消除数据倾斜②代码的执行效率问题,阻塞或者性能问题③TaskManager的内存大小导致反压

        案例:流任务出现高反压Source算子消费上游的Kafka具有3个分区,而该flinkSql流任务整体并行度只有1,需要将该任务整体并行度设为3,让一个并行去消费Kafka的分区.设置参数sql.env.parallelism=3;如果仅修改该任务整体并行度的话,会出现Flink资源不足,因为该流任务只有1个TaskManager和1个Slot,最大只能提供1x1=1个并行度,还需设置该任务每个TaskManager包含的Slot数量为3,设置参数Taskmanager.numberOfTaskSlots=3  
## 性能调优
**hadoop**:减少数据的传输量|尽量使用内存|减少磁盘IO次数|增大任务并行数|根据集群及网络情况来调优

    管理员角度:①硬件选择②操作系统参数调优③JVM参数调优④Hadoop参数调优

    用户角度:①应用程序编写规范:设置Combiner,选择合理的Writable类型②作业级别参数调优:规划合理的任务数目(map和reduce数)|增加输入文件副本数|设置失败容忍度|提高作业优先级|设置任务超时时间等③任务级别参数调优:MapTask调优(Read|Map|Collect|Spill|Merge)、ReduceTask调优(shuflle(copy)|merge|sort|reduce|write)

    存储HDFS小文件优化:①对小文件进行归档(har),将小文件存储成sequenceFile文件②采用combineFileInputFormat来作为输入③对于大量小文件job,可以启用jvm重用

    MapReduce优化:
        ①数据输入:合并小文件|采用CombineTextInputFormat来作为输入,解决输入端大量小文件
        ②map阶段:增加缓冲区大小;增加缓冲区的溢写比例;较少对溢写文件的merge次数;10个文件改为一次20个merge|采用combiner提前合并,减少IO
        ③reduce阶段:合理设置map和reduce数|设置map reduce共存|规避使用reduce|增加每个reduce从map取数的并行度|增大reduce端存储数据内存的大小
        ④IO传输:采用数据压缩的方式,减少网络IO时间.按照snappy和LZOP压缩编码器|使用SequenceFile二进制文件
        ⑤参数调优:资源相关参数|容错相关参数
        ⑥整体:增大MapTask和ReduceTask的内存大小|增大MapTask和ReduceTask的cpu核数|增大每个container的cpu核数和内存大小|调整每个MapTask和ReduceTask的重试次数
    
    数据倾斜:解决思路包含数据角度(预处理,数据过滤,模型设计)、业务角度、程序层面(mr|sql|spark算子)、调参层面(利用spark和hive自带的参数来优化)四种.

**hive**:参数调优|压缩存储|sql优化

    参数调优:Fetch抓取|本地模式|并行执行|jvm重用|推测执行

    压缩存储:行存储TextFile|SequenceFiles;列存储RCFile|ORCFile|Parquet;压缩的选择:压缩比率|压缩解压缩速度|是否支持Split(常用的是snappy压缩方法)
    
    SQL优化:join|where|count distinct|union|group by|等
    
    数据倾斜:①sql:count distinct|group by|join(map join|skewjoin)②参数:开启map端aggr|开启数据倾斜时负载均衡(hive.groupby.skewindata=true)

**spark**:开发过程中的优化|运行前的资源参数设置调优|运行中的数据倾斜的解决方案

    开发调优:①避免创建重复RDD②复用RDD③对多次使用的RDD持久化④避免shuffle算子⑤用mapside预聚合shuffle操作⑥使用高性能算子⑦广播大变量⑧Kryo优化序列化性能⑨优化数据结构

    数据倾斜:①Hive预处理②过滤少数导致倾斜的key③提高shuffle操作的并行度④两阶段聚合⑤将reducejoin转为mapjoin⑥采样倾斜key并分拆join操作⑦使用随机前缀和扩容RDD进行join

    Shuffle调优:①HashShuffleManager:未优化的HashShuffle会产生大量的中间磁盘文件影响性能;优化后的HashShuffle,就不再是每个mapTask为下游的每个reduceTask生成一个磁盘文件,而是一个executor为一个reduceTask生成一个磁盘文件②SortShuffleManager:普通运行机制,溢写到磁盘之前,先按照数据的key进行排序,排序后分批次写入磁盘,默认每批次1w条数据;bypass运行机制,mapTask数据溢写到磁盘之前不会对数据进行排序

    Spark与MapReduce相比,Spark运行效率更高原因:①基于内存计算,减少低效的磁盘交互②基于DAG高效的调度算法③容错机制Linage

**flink**:如何处理生产环境中的数据倾斜问题

    表现:任务节点频繁出现反压,增加并行度也不能解决问题;部分节点出现OOM异常,是因为大量的数据集中在某个节点上,导致该节点内存被爆,任务失败重启

    原因:业务上有严重的数据热点.技术上大量使用了KeyBy、GroupBy等操作,错误的使用了分组Key,人为产生数据热点

    定位反压:WebUI自带的反压监控（直接方式）、Flink Task Metrics（间接方式）.通过监控反压的信息，可以获取到数据处理瓶颈的Subtask;定位数据倾斜:WebUI自带Subtask接收和发送的数据量。当Subtasks 之间处理的数据量有较大的差距，则该Subtask出现数据倾斜。

    思路:业务上要尽量避免热点key的设计;技术上,打散原来的热点key,避免直接聚合;数据源source消费不均匀时,通过调整Flink并行度，解决数据源消费不均匀或者数据源反压的情况;两阶段聚合解决 KeyBy（加盐局部聚合+去盐全局聚合）