(window.webpackJsonp=window.webpackJsonp||[]).push([[362],{693:function(e,s,a){"use strict";a.r(s);var i=a(4),t=Object(i.a)({},(function(){var e=this,s=e._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("h1",{attrs:{id:"分布式系统-分布式缓存及方案实现"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式系统-分布式缓存及方案实现"}},[e._v("#")]),e._v(" 分布式系统 - 分布式缓存及方案实现")]),e._v(" "),s("h2",{attrs:{id:"缓存基础和分布式缓存"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#缓存基础和分布式缓存"}},[e._v("#")]),e._v(" 缓存基础和分布式缓存")]),e._v(" "),s("h3",{attrs:{id:"缓存基础和本地缓存"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#缓存基础和本地缓存"}},[e._v("#")]),e._v(" 缓存基础和本地缓存")]),e._v(" "),s("ul",[s("li",[s("p",[s("strong",[e._v("本地缓存")]),e._v(" ：指的是在应用中的缓存组件，其最大的优点是应用和cache是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适；同时，它的缺点也是应为缓存跟应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费。")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("分布式缓存")]),e._v(" ：指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。")])])]),e._v(" "),s("p",[e._v("目前各种类型的缓存都活跃在成千上万的应用服务中，还没有一种缓存方案可以解决一切的业务场景或数据类型，我们需要根据自身的特殊场景和背景，选择最适合的缓存方案。缓存的使用是程序员、架构师的必备技能，好的程序员能根据数据类型、业务场景来准确判断使用何种类型的缓存，如何使用这种缓存，以最小的成本最快的效率达到最优的目的。")]),e._v(" "),s("h3",{attrs:{id:"分布式缓存介绍"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式缓存介绍"}},[e._v("#")]),e._v(" 分布式缓存介绍")]),e._v(" "),s("h2",{attrs:{id:"分布式缓存的实现方案"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式缓存的实现方案"}},[e._v("#")]),e._v(" 分布式缓存的实现方案")]),e._v(" "),s("h3",{attrs:{id:"memcached缓存"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#memcached缓存"}},[e._v("#")]),e._v(" memcached缓存")]),e._v(" "),s("p",[e._v("memcached是应用较广的开源分布式缓存产品之一，它本身其实不提供分布式解决方案。在服务端，memcached集群环境实际就是一个个memcached服务器的堆积，环境搭建较为简单；cache的分布式主要是在客户端实现，通过客户端的路由处理来达到分布式解决方案的目的。客户端做路由的原理非常简单，应用服务器在每次存取某key的value时，通过某种算法把key映射到某台memcached服务器nodeA上，因此这个key所有操作都在nodeA上，结构图如图6、图7所示。")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/willpast/image/blog/ka_java/arch-x-cache-6.png",alt:"img"}})]),e._v(" "),s("p",[e._v("图6 memcached客户端路由图")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/willpast/image/blog/ka_java/arch-x-cache-7.png",alt:"img"}})]),e._v(" "),s("p",[e._v("图7 memcached一致性hash示例图")]),e._v(" "),s("p",[e._v("memcached客户端采用一致性hash算法作为路由策略，如图7，相对于一般hash（如简单取模）的算法，一致性hash算法除了计算key的hash值外，还会计算每个server对应的hash值，然后将这些hash值映射到一个有限的值域上（比如0~2^32）。通过寻找hash值大于hash(key)的最小server作为存储该key数据的目标server。如果找不到，则直接把具有最小hash值的server作为目标server。同时，一定程度上，解决了扩容问题，增加或删除单个节点，对于整个集群来说，不会有大的影响。最近版本，增加了虚拟节点的设计，进一步提升了可用性。")]),e._v(" "),s("p",[e._v("memcached是一个高效的分布式内存cache，了解memcached的内存管理机制，才能更好的掌握memcached，让我们可以针对我们数据特点进行调优，让其更好的为我所用。我们知道memcached仅支持基础的key-\nvalue键值对类型数据存储。在memcached内存结构中有两个非常重要的概念：slab和chunk。如图8所示。")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/willpast/image/blog/ka_java/arch-x-cache-8.png",alt:"img"}})]),e._v(" "),s("p",[e._v("图8 memcached内存结构图")]),e._v(" "),s("p",[e._v("slab是一个内存块，它是memcached一次申请内存的最小单位。在启动memcached的时候一般会使用参数-\nm指定其可用内存，但是并不是在启动的那一刻所有的内存就全部分配出去了，只有在需要的时候才会去申请，而且每次申请一定是一个slab。Slab的大小固定为1M（1048576\nByte），一个slab由若干个大小相等的chunk组成。每个chunk中都保存了一个item结构体、一对key和value。")]),e._v(" "),s("p",[e._v("虽然在同一个slab中chunk的大小相等的，但是在不同的slab中chunk的大小并不一定相等，在memcached中按照chunk的大小不同，可以把slab分为很多种类（class），默认情况下memcached把slab分为40类（class1～class40），在class\n1中，chunk的大小为80字节，由于一个slab的大小是固定的1048576字节（1M），因此在class1中最多可以有13107个chunk（也就是这个slab能存最多13107个小于80字节的key-\nvalue数据）。")]),e._v(" "),s("p",[e._v("memcached内存管理采取预分配、分组管理的方式，分组管理就是我们上面提到的slab\nclass，按照chunk的大小slab被分为很多种类。内存预分配过程是怎样的呢?\n向memcached添加一个item时候，memcached首先会根据item的大小，来选择最合适的slab\nclass：例如item的大小为190字节，默认情况下class 4的chunk大小为160字节显然不合适，class\n5的chunk大小为200字节，大于190字节，因此该item将放在class\n5中（显然这里会有10字节的浪费是不可避免的），计算好所要放入的chunk之后，memcached会去检查该类大小的chunk还有没有空闲的，如果没有，将会申请1M（1个slab）的空间并划分为该种类chunk。例如我们第一次向memcached中放入一个190字节的item时，memcached会产生一个slab\nclass\n2（也叫一个page），并会用去一个chunk，剩余5241个chunk供下次有适合大小item时使用，当我们用完这所有的5242个chunk之后，下次再有一个在160～200字节之间的item添加进来时，memcached会再次产生一个class\n5的slab（这样就存在了2个pages）。")]),e._v(" "),s("p",[e._v("总结来看，memcached内存管理需要注意的几个方面：")]),e._v(" "),s("ul",[s("li",[e._v("chunk是在page里面划分的，而page固定为1m，所以chunk最大不能超过1m。")]),e._v(" "),s("li",[e._v("chunk实际占用内存要加48B，因为chunk数据结构本身需要占用48B。")]),e._v(" "),s("li",[e._v("如果用户数据大于1m，则memcached会将其切割，放到多个chunk内。")]),e._v(" "),s("li",[e._v("已分配出去的page不能回收。")])]),e._v(" "),s("p",[e._v("对于key-\nvalue信息，最好不要超过1m的大小；同时信息长度最好相对是比较均衡稳定的，这样能够保障最大限度的使用内存；同时，memcached采用的LRU清理策略，合理甚至过期时间，提高命中率。")]),e._v(" "),s("p",[e._v("无特殊场景下，key-\nvalue能满足需求的前提下，使用memcached分布式集群是较好的选择，搭建与操作使用都比较简单；分布式集群在单点故障时，只影响小部分数据异常，目前还可以通过Magent缓存代理模式，做单点备份，提升高可用；整个缓存都是基于内存的，因此响应时间是很快，不需要额外的序列化、反序列化的程序，但同时由于基于内存，数据没有持久化，集群故障重启数据无法恢复。高版本的memcached已经支持CAS模式的原子操作，可以低成本的解决并发控制问题。")]),e._v(" "),s("h3",{attrs:{id:"redis缓存"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#redis缓存"}},[e._v("#")]),e._v(" Redis缓存")]),e._v(" "),s("blockquote",[s("p",[e._v("Redis是一款内存高速缓存数据库。Redis全称为："),s("strong",[e._v("Remote Dictionary Server")]),e._v("\n（远程数据服务），使用C语言编写，Redis是一个key-\nvalue存储系统（键值存储系统），支持丰富的数据类型，如：String、list、set、zset、hash。")])]),e._v(" "),s("p",[e._v("Redis是一种支持key-\nvalue等多种数据结构的存储系统。可用于缓存，事件发布或订阅，高速队列等场景。支持网络，提供字符串，哈希，列表，队列，集合结构直接存取，基于内存，可持久化。同时性能强劲，具有复制特性以及解决问题而生的独一无二的数据模型。它可以存储键值对与5种不同类型的值之间的映射，可以将存储在内存的键值对数据持久化到硬盘，可以使用复制特性来扩展读性能，还可以使用客户端分片来扩展写性能。")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/willpast/image/blog/ka_java/arch-x-cache-9.png",alt:"img"}})]),e._v(" "),s("p",[e._v("图9 Redis数据模型图")]),e._v(" "),s("p",[e._v("如图9，Redis内部使用一个redisObject对象来标识所有的key和value数据，redisObject最主要的信息如图所示：type代表一个value对象具体是何种数据类型，encoding是不同数据类型在Redis内部的存储方式，比如——type=string代表value存储的是一个普通字符串，那么对应的encoding可以是raw或是int，如果是int则代表世界Redis内部是按数值类型存储和表示这个字符串。")]),e._v(" "),s("p",[e._v("图9左边的raw列为对象的编码方式：字符串可以被编码为raw（一般字符串）或Rint（为了节约内存，Redis会将字符串表示的64位有符号整数编码为整数来进行储存）；列表可以被编码为ziplist或linkedlist，ziplist是为节约大小较小的列表空间而作的特殊表示；集合可以被编码为intset或者hashtable，intset是只储存数字的小集合的特殊表示；hash表可以编码为zipmap或者hashtable，zipmap是小hash表的特殊表示；有序集合可以被编码为ziplist或者skiplist格式，ziplist用于表示小的有序集合，而skiplist则用于表示任何大小的有序集合。")]),e._v(" "),s("p",[e._v("从网络I/O模型上看，Redis使用单线程的I/O复用模型，自己封装了一个简单的AeEvent事件处理框架，主要实现了epoll、kqueue和select。对于单纯只有I/O操作来说，单线程可以将速度优势发挥到最大，但是Redis也提供了一些简单的计算功能，比如排序、聚合等，对于这些操作，单线程模型实际会严重影响整体吞吐量，CPU计算过程中，整个I/O调度都是被阻塞住的，在这些特殊场景的使用中，需要额外的考虑。相较于memcached的预分配内存管理，Redis使用现场申请内存的方式来存储数据，并且很少使用free-\nlist等方式来优化内存分配，会在一定程度上存在内存碎片。Redis跟据存储命令参数，会把带过期时间的数据单独存放在一起，并把它们称为临时数据，非临时数据是永远不会被剔除的，即便物理内存不够，导致swap也不会剔除任何非临时数据（但会尝试剔除部分临时数据）。")]),e._v(" "),s("p",[e._v("我们描述Redis为内存数据库，作为缓存服务，大量使用内存间的数据快速读写，支持高并发大吞吐；而作为数据库，则是指Redis对缓存的持久化支持。Redis由于支持了非常丰富的内存数据库结构类型，如何把这些复杂的内存组织方式持久化到磁盘上?\nRedis的持久化与传统数据库的方式差异较大，Redis一共支持四种持久化方式，主要使用的两种：")]),e._v(" "),s("ul",[s("li",[s("p",[s("strong",[e._v("定时快照方式(snapshot)")]),e._v(" ：该持久化方式实际是在Redis内部一个定时器事件，每隔固定时间去检查当前数据发生的改变次数与时间是否满足配置的持久化触发的条件，如果满足则通过操作系统fork调用来创建出一个子进程，这个子进程默认会与父进程共享相同的地址空间，这时就可以通过子进程来遍历整个内存来进行存储操作，而主进程则仍然可以提供服务，当有写入时由操作系统按照内存页（page）为单位来进行copy-on-write保证父子进程之间不会互相影响。它的缺点是快照只是代表一段时间内的内存映像，所以系统重启会丢失上次快照与重启之间所有的数据。")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("基于语句追加文件的方式(aof)")]),e._v(" ：aof方式实际类似MySQl的基于语句的binlog方式，即每条会使Redis内存数据发生改变的命令都会追加到一个log文件中，也就是说这个log文件就是Redis的持久化数据。 aof的方式的主要缺点是追加log文件可能导致体积过大，当系统重启恢复数据时如果是aof的方式则加载数据会非常慢，几十G的数据可能需要几小时才能加载完，当然这个耗时并不是因为磁盘文件读取速度慢，而是由于读取的所有命令都要在内存中执行一遍。另外由于每条命令都要写log，所以使用aof的方式，Redis的读写性能也会有所下降。")])])]),e._v(" "),s("p",[e._v("Redis的持久化使用了Buffer I/O，所谓Buffer I/O是指Redis对持久化文件的写入和读取操作都会使用物理内存的Page\nCache，而大多数数据库系统会使用Direct I/O来绕过这层Page\nCache并自行维护一个数据的Cache。而当Redis的持久化文件过大（尤其是快照文件），并对其进行读写时，磁盘文件中的数据都会被加载到物理内存中作为操作系统对该文件的一层Cache，而这层Cache的数据与Redis内存中管理的数据实际是重复存储的。虽然内核在物理内存紧张时会做Page\nCache的剔除工作，但内核很可能认为某块Page\nCache更重要，而让你的进程开始Swap，这时你的系统就会开始出现不稳定或者崩溃了，因此在持久化配置后，针对内存使用需要实时监控观察。")]),e._v(" "),s("p",[e._v("与memcached客户端支持分布式方案不同，Redis更倾向于在服务端构建分布式存储，如图10、11。")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/willpast/image/blog/ka_java/arch-x-cache-10.png",alt:"img"}})]),e._v(" "),s("p",[e._v("图10 Redis分布式集群图1")]),e._v(" "),s("p",[s("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/willpast/image/blog/ka_java/arch-x-cache-11.png",alt:"img"}})]),e._v(" "),s("p",[e._v("图11 Redis分布式集群图2")]),e._v(" "),s("p",[e._v("Redis\nCluster是一个实现了分布式且允许单点故障的Redis高级版本，它没有中心节点，具有线性可伸缩的功能。如图11，其中节点与节点之间通过二进制协议进行通信，节点与客户端之间通过ascii协议进行通信。在数据的放置策略上，Redis\nCluster将整个key的数值域分成2的14次方16384个hash槽，每个节点上可以存储一个或多个hash槽，也就是说当前Redis\nCluster支持的最大节点数就是16384。Redis Cluster使用的分布式算法也很简单："),s("code",[e._v("crc16( key ) % HASH_SLOTS_NUMBER")]),e._v("。整体设计可总结为：")]),e._v(" "),s("ul",[s("li",[e._v("数据hash分布在不同的Redis节点实例上；")]),e._v(" "),s("li",[e._v("M/S的切换采用Sentinel；")]),e._v(" "),s("li",[e._v("写：只会写master Instance，从sentinel获取当前的master Instance；")]),e._v(" "),s("li",[e._v("读：从Redis Node中基于权重选取一个Redis Instance读取，失败/超时则轮询其他Instance；Redis本身就很好的支持读写分离，在单进程的I/O场景下，可以有效的避免主库的阻塞风险；")])]),e._v(" "),s("p",[e._v("通过RPC服务访问，RPC server端封装了Redis客户端，客户端基于Jedis开发。\n可以看到，通过集群+主从结合的设计，Redis在扩展和稳定高可用性能方面都是比较成熟的。但是，在数据一致性问题上，Redis没有提供CAS操作命令来保障高并发场景下的数据一致性问题，不过它却提供了事务的功能，Redis的Transactions提供的并不是严格的ACID的事务（比如一串用EXEC提交执行的命令，在执行中服务器宕机，那么会有一部分命令执行了，剩下的没执行）。但是这个Transactions还是提供了基本的命令打包执行的功能（在服务器不出问题的情况下，可以保证一连串的命令是顺序在一起执行的，中间有会有其它客户端命令插进来执行）。Redis还提供了一个Watch功能，你可以对一个key进行Watch，然后再执行Transactions，在这过程中，如果这个Watched的值进行了修改，那么这个Transactions会发现并拒绝执行。在失效策略上，Redis支持多大6种的数据淘汰策略：")]),e._v(" "),s("ul",[s("li",[e._v("volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰；")]),e._v(" "),s("li",[e._v("volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰；")]),e._v(" "),s("li",[e._v("volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 ；")]),e._v(" "),s("li",[e._v("allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰；")]),e._v(" "),s("li",[e._v("allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰；")]),e._v(" "),s("li",[e._v("no-enviction（驱逐）：禁止驱逐数据。")])]),e._v(" "),s("p",[e._v("个人总结了以下多种Web应用场景，在这些场景下可以充分的利用Redis的特性，大大提高效率。")]),e._v(" "),s("ul",[s("li",[s("p",[s("strong",[e._v("在主页中显示最新的项目列表")]),e._v(" ：Redis使用的是常驻内存的缓存，速度非常快。LPUSH用来插入一个内容ID，作为关键字存储在列表头部。LTRIM用来限制列表中的项目数最多为5000。如果用户需要的检索的数据量超越这个缓存容量，这时才需要把请求发送到数据库。")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("删除和过滤")]),e._v(" ：如果一篇文章被删除，可以使用LREM从缓存中彻底清除掉。")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("排行榜及相关问题")]),e._v(" ：排行榜（leader board）按照得分进行排序。ZADD命令可以直接实现这个功能，而ZREVRANGE命令可以用来按照得分来获取前100名的用户，ZRANK可以用来获取用户排名，非常直接而且操作容易。")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("按照用户投票和时间排序")]),e._v(" ：排行榜，得分会随着时间变化。LPUSH和LTRIM命令结合运用，把文章添加到一个列表中。一项后台任务用来获取列表，并重新计算列表的排序，ZADD命令用来按照新的顺序填充生成列表。列表可以实现非常快速的检索，即使是负载很重的站点。")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("过期项目处理")]),e._v(" ：使用Unix时间作为关键字，用来保持列表能够按时间排序。对current_time和time_to_live进行检索，完成查找过期项目的艰巨任务。另一项后台任务使用ZRANGE…WITHSCORES进行查询，删除过期的条目。")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("计数")]),e._v(" ：进行各种数据统计的用途是非常广泛的，比如想知道什么时候封锁一个IP地址。INCRBY命令让这些变得很容易，通过原子递增保持计数；GETSET用来重置计数器；过期属性用来确认一个关键字什么时候应该删除。")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("特定时间内的特定项目")]),e._v(" ：这是特定访问者的问题，可以通过给每次页面浏览使用SADD命令来解决。SADD不会将已经存在的成员添加到一个集合。")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("Pub/Sub")]),e._v(" ：在更新中保持用户对数据的映射是系统中的一个普遍任务。Redis的pub/sub功能使用了SUBSCRIBE、UNSUBSCRIBE和PUBLISH命令，让这个变得更加容易。")])]),e._v(" "),s("li",[s("p",[s("strong",[e._v("队列")]),e._v(" ：在当前的编程中队列随处可见。除了push和pop类型的命令之外，Redis还有阻塞队列的命令，能够让一个程序在执行时被另一个程序添加到队列。 实际工程中，对于缓存的应用可以有多种的实战方式，包括侵入式硬编码，抽象服务化应用，以及轻量的注解式使用等。本文将主要介绍下注解式方式。")])])]),e._v(" "),s("h2",{attrs:{id:"分布式缓存的实现技术"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式缓存的实现技术"}},[e._v("#")]),e._v(" 分布式缓存的实现技术")]),e._v(" "),s("blockquote",[s("p",[e._v("在分布式缓存的实现方案中，有哪些常见的技术实现要点呢？从Redis的视角看，在它的实现中主要包含如下实现技术要点:")])]),e._v(" "),s("ul",[s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-rdb-aof.html"}},[e._v("Redis进阶 - 持久化：RDB和AOF机制详解")]),e._v(" "),s("ul",[s("li",[e._v("为了防止数据丢失以及服务重启时能够恢复数据，Redis支持数据的持久化，主要分为两种方式，分别是RDB和AOF; 当然实际场景下还会使用这两种的混合模式。")])])],1),e._v(" "),s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-pub-sub.html"}},[e._v("Redis进阶 - 消息传递：发布订阅模式详解")]),e._v(" "),s("ul",[s("li",[e._v("Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。")])])],1),e._v(" "),s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-event.html"}},[e._v("Redis进阶 - 事件：Redis事件机制详解")]),e._v(" "),s("ul",[s("li",[e._v("Redis 采用事件驱动机制来处理大量的网络IO。它并没有使用 libevent 或者 libev 这样的成熟开源方案，而是自己实现一个非常简洁的事件驱动库 ae_event。")])])],1),e._v(" "),s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-trans.html"}},[e._v("Redis进阶 - 事务：Redis事务详解")]),e._v(" "),s("ul",[s("li",[e._v("Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。")])])],1),e._v(" "),s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-copy.html"}},[e._v("Redis进阶 - 高可用：主从复制详解")]),e._v(" "),s("ul",[s("li",[e._v("我们知道要避免单点故障，即保证高可用，便需要冗余（副本）方式提供集群服务。而Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。本文主要阐述Redis的主从复制。")])])],1),e._v(" "),s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-sentinel.html"}},[e._v("Redis进阶 - 高可用：哨兵机制（Redis Sentinel）详解")]),e._v(" "),s("ul",[s("li",[e._v("在上文主从复制的基础上，如果注节点出现故障该怎么办呢？ 在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的问题。")])])],1),e._v(" "),s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-cluster.html"}},[e._v("Redis进阶 - 高可拓展：分片技术（Redis Cluster）详解")]),e._v(" "),s("ul",[s("li",[e._v("前面两篇文章，主从复制和哨兵机制保障了高可用，就读写分离而言虽然slave节点来扩展主从的读并发能力，但是写能力和存储能力是无法进行扩展的，就只能是master节点能够承载的上限。如果面对海量数据那么必然需要构建master（主节点分片)之间的集群，同时必然需要吸收高可用（主从复制和哨兵机制）能力，即每个master分片节点还需要有slave节点，这是分布式系统中典型的纵向扩展（集群的分片技术）的体现；所以在Redis 3.0版本中对应的设计就是Redis Cluster。")])])],1)]),e._v(" "),s("p",[e._v("对于全面深入学习Redis知识体系，可以参看：[Redis知识体系详解](/md/db/nosql-redis/db-redis-\noverview.html)")]),e._v(" "),s("p",[s("img",{attrs:{src:"/images/db/redis/db-redis-overview.png",alt:""}})]),e._v(" "),s("h2",{attrs:{id:"分布式缓存中常见的问题和解决方案"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分布式缓存中常见的问题和解决方案"}},[e._v("#")]),e._v(" 分布式缓存中常见的问题和解决方案")]),e._v(" "),s("blockquote",[s("p",[e._v("缓存中存在的问题如下，具体可以看：[Redis进阶 - 缓存问题：一致性, 穿击, 穿透, 雪崩, 污染等](/md/db/nosql-\nredis/db-redis-x-cache.html)")])]),e._v(" "),s("ul",[s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-cache.html#缓存穿透"}},[e._v("缓存穿透问题")])],1),e._v(" "),s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-cache.html#缓存击穿"}},[e._v("缓存击穿问题")])],1),e._v(" "),s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-cache.html#缓存雪崩"}},[e._v("缓存雪崩问题")])],1),e._v(" "),s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-cache.html#缓存污染或满了"}},[e._v("缓存污染（或满了）")]),e._v(" "),s("ul",[s("li",[e._v("最大缓存设置多大")]),e._v(" "),s("li",[e._v("缓存淘汰策略")])])],1),e._v(" "),s("li",[s("RouterLink",{attrs:{to:"/md/db/nosql-redis/db-redis-x-cache.html#数据库和缓存一致性"}},[e._v("数据库和缓存一致性问题")]),e._v(" "),s("ul",[s("li",[e._v("4种相关模式\n"),s("ul",[s("li",[e._v("Cache aside")]),e._v(" "),s("li",[e._v("Read through")]),e._v(" "),s("li",[e._v("Write through")]),e._v(" "),s("li",[e._v("Write behind caching")])])]),e._v(" "),s("li",[e._v("方案：队列 + 重试机制")]),e._v(" "),s("li",[e._v("方案：异步更新缓存(基于订阅binlog的同步机制)")])])],1)]),e._v(" "),s("h2",{attrs:{id:"参考文章"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[e._v("#")]),e._v(" 参考文章")]),e._v(" "),s("ul",[s("li",[s("p",[e._v("https://juejin.cn/post/6844903444864581640")])]),e._v(" "),s("li",[s("p",[e._v("https://juejin.im/post/687260007384373658")])])])])}),[],!1,null,null,null);s.default=t.exports}}]);