(window.webpackJsonp=window.webpackJsonp||[]).push([[447],{778:function(a,e,t){"use strict";t.r(e);var n=t(4),r=Object(n.a)({},(function(){var a=this,e=a._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[e("h2",{attrs:{id:"数据处理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据处理"}},[a._v("#")]),a._v(" 数据处理")]),a._v(" "),e("h3",{attrs:{id:"数据仓库"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据仓库"}},[a._v("#")]),a._v(" 数据仓库")]),a._v(" "),e("p",[a._v("数据仓库(ODS|CDM|TDM|ADM)")]),a._v(" "),e("p",[e("strong",[a._v("不成熟数仓")]),a._v(":具备部分数仓规范或存在多套规范约束,且在落地实施的过程中,未能严格落地实施,导致数据仓库建设比较混乱")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("方法论:①识环境(组织|业务|技术)②找问题③理业务(业务流|数据流)④定框架(技术架构)⑤建标准(分层|数据域|规范)⑥落流程(建模|报表|测试)⑦强执行(计划|pm)⑧善总结(总结经验|反哺流程)\n")])])]),e("p",[e("strong",[a._v("模型设计原则")]),a._v(":高内聚低耦合|核心扩展模型分离|公共逻辑下沉|成本性能平衡|一致性|命名清晰可理解")]),a._v(" "),e("p",[e("strong",[a._v("好的模型")]),a._v(":应该更好的组织、存储数据,以便在访问性能、数据成本、使用效率和数据质量之间找到最佳平衡点;稳定/通用/复用/易用.")]),a._v(" "),e("p",[e("strong",[a._v("数仓优劣")]),a._v(":通过osm(Object-Strategy-Measure)指标体系来衡量.O:数仓优劣判断;S:数据监控、元数据管理、业务流程的理解、核心模型相对稳定、高内聚低耦合;M:核心度量指标如下")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("生产指标:跨层引用率/表引用数/引用链路长度/表命名规范率/数据泄露率;使用指标:数据准时率/数据查阅数/数据用户数占比/数据授权用户数/自助取数平均耗时        \n\n金服指标:质量(故障数、IPH准点率、DQC达标率)、成本(存储和计算)、效率(开发人效、查询效率)、安全(敏感数据标注率)、体验(产品使用:手写查询率|高频产品使用率;查询体验:不良查询率)\n\n琅琊榜:数据的生命周期是从产生、加工、应用、消亡的过程,分为6个阶段:规范设计、模型建设、质量管理、数据应用、安全审计、资源维护\n\n琅琊榜指标:数据规范(建模:命名不规范;注释不完整;责任人缺失/流向:夸层依赖率;引用链路过长)、数据质量(准时:iph准点率/准确:dqc达标率)、应用体验(查询:平均查询时长/内容:ods层访问率)、计算资源(有效计算:失败任务率/计算效率:倾斜率;高耗时任务率)、存储资源(有效存储:无效存储率/存储效率:小文件率;生命周期管理率)    \n\nETL任务评分专利:新鲜度+复杂度+成本度(0.25计算成本、0.25存储成本、0.5执行时长)+依赖度+查询度\n")])])]),e("p",[e("strong",[a._v("纵向主题域")]),a._v(":是把那些关联紧密但不同的数据主题,交汇融合到一个更大的主题域当中,也更容易被分析人员调取利用.分域方法:①业务过程②业务系统③业务部门④功能或应用⑤行业经验")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("数据域:面向业务过程,将业务活动事件进行抽象的集合,如下单、支付、退款都是业务过程,针对公共明细层(DWD)进行主题划分.\n\n主题域:面向业务分析,将业务过程或者维度进行抽象的集合,针对公共汇总层(DWS)进行数据域划分.\n")])])]),e("p",[e("strong",[a._v("横向分层优点")]),a._v(":隔离原始数据(解耦)、复杂问题简单化、增加数据复用性、数据流向清晰(管理)")]),a._v(" "),e("p",[e("strong",[a._v("ODS贴源层")]),a._v(":全域统一存储.保留原始业务流程数据,与业务系统基本保持一致,存放原始数据,不做处理\n.日志收集:接入层(disk|sdk)、采集层(log-agent)、传输层(log-collector)和缓存分发层(controller到kafka)\n.db收集:业务系统(binlog)、采集服务(canal)、数据缓存服务(kafka)、离线数仓ODS(flink)\n.MT埋点:需求、配置、埋点、验证、上报、各业务分发处理;"),e("br"),a._v("\n.MY埋点:spm位置模型:a站点|b页面|c区块|d点位;scm内容模型:a投放平台|b内容分类|c内容id|d算法版本|e投放范围;")]),a._v(" "),e("p",[e("strong",[a._v("CDM数仓层")]),a._v(":标准化的数据底座,又细分为DWD和DWS.它的主要作用是完成数据加工与整合、建立一致性的维度、构建可复用的面向分析和统计的明细事实表以及汇总公共粒度的指标\n.明细层DWD:业务过程建模(业务过程ID+维度+事实),主要对ODS层数据进行清洗、归因、规范化处理\n.汇总层DWS:分析主体建模(分析主体ID+维度+指标),构建公共粒度的汇总指标多维事实宽表\n.MT主题域:由传统TearData金融业务主题域(参与人|协议|事件|资源|营销|财务)向面向分析主题域(用户|商家|交易|营销|风控|流量)转换;\n①ods_view隔离业务数据脱敏②base清洗标准化③topic领域拆分,范式建模④mid_logic单实体|mid_topic_view多实体⑤mid维度加工⑥detail多维事实⑦summary\n.ant主题域:流量|设备|用户|营销|商家|数字化|产品;\n业务过程:①采集:唤起刷脸|刷脸授权|点击拍照按钮|图像采集②识别:提特征|活体|意愿判断|检索|风控|zid确定③确认:0411页面|识别结果④支付:标准|极速")]),a._v(" "),e("p",[e("strong",[a._v("TDM标签层")]),a._v(":面向对象建模,对跨业务板块、数据域的对象进行整合,通过ID-Mapping把各业务板块、业务过程中同一对象的数据打通,形成全域标签体系,方便分析挖掘\n.建设:确定对象(人|物|关系)、ID打通、标签设计(标签类目|标签和标签值)、标签表设计;标签搭建步骤:①还原业务流程②覆盖生命周期③明确商业目标④从策略推标签\n.标签体系:①CDP:基本信息、LBS、关系、行为、偏好、用户分级、金融属性、营销属性、风险属性②FUP:基础属性、用户分层、兴趣偏好设、用户行为、营销属性、风险属性\n.ant标签分类:事实类(基础标签一般具备可复用、可解释、可增长的特性)、刻画类(无行业特征,不随外界变化预测;usernet评测;基础信息|位置信息|人生阶段|职业信息|财富信息)、意图类(有行业特征,后续行为的预测;置信度衡量;购物偏好|刷脸意愿)\n.ant标签平台:目标是实现统一的标签自动生成、评估、推荐,提供智能化、自动化的标签生产及标签效果评估体系.\n四个一级生产工厂：①基于基础数据标签挖掘工厂②基于大模型实现sql自动生成标签工厂③基于图算法挖掘的标签自动扩散工厂④基于多模态数据标签挖掘工厂\n.标签生产:①原子标签②衍生标签:由原子标签以表达式的形式组合③模型标签:按需求通过模型训练形成\n.标签框架:①基于营销触点的用户标签体系,先把用户分为不同的营销阶段,再细分每个阶段需要做的事情和标签②基于增长漏斗的AARRR模型③用户价值分层模型RFM④基于用户偏好的模型")]),a._v(" "),e("p",[e("strong",[a._v("ADM应用层")]),a._v(":灵活支撑业务需求.面向业务的特殊需要加工业务特定数据,以满足业务及性能需求,向特定应用组装应用数据(多个维度组合+指标).")]),a._v(" "),e("p",[e("strong",[a._v("数仓层建设过程")]),a._v("(点线面体)以维度建模为基础,构建总线矩阵,划分业务板块,定义主题域、数据域、业务过程、维度、原子指标、修饰类型、派生指标,确定维度表、事实表的模型设计")]),a._v(" "),e("p",[e("strong",[a._v("kimball维度模型")]),a._v(":按照事实表、维度表来构建数仓、集市,从分析决策的需求出发构建模型,为分析需求服务,重点关注如何快速地完成需求,且具有较好的大规模复杂查询性能;①选择业务过程②声明粒度③确认维度④确认事实")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("分类:\n①高层模型,直接产出目标是创建高层维度模型图,它是对业务过程中的维表和事实表的图形描述.确定维表创建初始属性列表,为每个事实表创建提议度量\n②详细模型,填补高层模型缺失的信息,不断测试模型能否满足业务需求,确保模型的完备性.确定每个维表的属性和事实表的度量,确定信息来源的位置、定义,确定属性和度量填入模型的初步业务规则\n\n特点:自上而下,业务驱动.这种方式建设周期短,用户能很快看到结果,简单易理解、性能好、可扩展性好;\n缺点:数据冗余,不能保证数据来源的一致性和准确性\n")])])]),e("p",[e("strong",[a._v("inmon范式模型")]),a._v(":①领域(主题域)建模,主要是针对业务模型进行抽象处理,生成领域(主题域)概念模型②逻辑建模,是将领域模型的概念实体以实体之间的关系进行数据库层次的逻辑化③物理建模")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("分类:\n①ERD(EntityRelationshipDiagram)层,描述业务的实体或主题域以及它们之间的关系\n②DIS(DataItemSet)层,描述数据模型中的关键字、属性以及细节数据之间的关系\n③物理层,描述数据模型的物理特性\n\n特点:自下而上,数据驱动.从整个企业的环境入手,建立数据仓库,要做很全面的设计,减少数据冗余,占用存储空间少,方便解耦;\n缺点:开发周期比较长,维护成本高\n\n1NF:每个属性值唯一,不具有多义性.要求属性具有原子性,即列不可再分解;\n2NF:每个非主属性必须完全依赖于整个主键,而非主键的一部分.要求记录有惟一标识,即不存在部分依赖;\n3NF:每个非主属性不能依赖于其他关系中的属性,要求字段没有冗余,即不存在传递依赖\n")])])]),e("p",[e("strong",[a._v("模型")]),a._v(":①星型模式是以事实表为中心,所有的维度表连接在事实表上,像星星一样②雪花模式是对星形模式的扩展,某些维表被规范化,进一步分解到维表中③星座模式是星型模式延伸而来,星型模式是基于一张事实表的,而星座模式是基于多张事实表的,共享维度信息④宽表模型:是基于维度模型的扩展,采用退化维度的方式,将不同维度的度量放入数据表的不同的列中,它更易于理解,易扩展")]),a._v(" "),e("p",[e("strong",[a._v("总线架构")]),a._v(":分步建立数据仓库,由数据集市组合成企业的数据仓库.但是在建立数据集市前,架构师要先设计出具有统一解释的标准化的维度和事实.一致性维度就好比企业范围内的一组总线,不同数据集市的事实的就好比插在这组总线上的元件,这也是称之为总线架构的原因.")]),a._v(" "),e("p",[e("strong",[a._v("一致性维度")]),a._v(":维度是用来反映业务的一类属性,这类属性的集合构成一个维度.强调维度一致性、共享性,事情发生的环境可以部分抽象出来、是有共性的.一致性维度是两个维度如果有关系,要么就是完全一样的,要么就是一个维度在数学意义上是另一个维度的子集.维度保持一致后,事实就可以保存在各个数据集市中,虽然在物理上是独立的,但在逻辑上由一致性维度使所有的数据集市是联系在一起,随时可以进行交叉探察等操作,也就组成了数据仓库.")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v(".维度表设计步骤:选择维度、确定主维度、梳理关系维表、定义维度属性\n.缓慢变化维:scd随时间发生变化的维度称为缓慢变化维.在维度建模理论中,有8种处理方式,包括基础的5种以及混合的3种,再加上大数据时代的2种极限型,共10种.0:保留原始值①直接覆盖②增加新行③增加新属性列④增加微型维度⑤微型维度与方式1支架表⑥将方式1属性增加到方式2维度⑦双重外键并且方式1与方式2结合⑧快照维度⑨历史拉链维度\n.退化维度:Kimball描述为操作型事务控制号码,保存为事实表中的退化维度.退化维度是没有对应维度表的维度键,没有修饰它的属性\n")])])]),e("p",[e("strong",[a._v("一致性事实")]),a._v(":事实涉及来自业务过程的度量,基本都以数量值表示.强调事实一致性,支持跨集市查询分析没有二义性;一致性事实需要保证两点:①是KPI的定义及计算方法要一致②是事实的单位要一致性;一致性维度将多个数据集市结合在一起,一致性事实保证不同数据集市间的事实数据可以交叉探查,一个分布式的数据仓库就建成.")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v(".事实表设计步骤:选择业务过程、声明粒度、确定维度、确定事实、冗余维度属性\n.事实表组成:①是由主键和外键组成的键值部分②是用来描述业务过程的事实度量.事实表的键值部分确定了事实表的粒度,事实表通过粒度和事实度量来描述业务过程\n.事实表分类:以粒度的不同来化分,事实表可以分为三类:\n    .事务事实表:描述业务过程事务层面的事实,每条记录代表一个事务事件,保留事务事件原始内容\n    .周期快照事实表:以具有规律性、可预见的时间间隔产生快照来记录事实,每行代表某个时间周期的一条记录,记录的事实是时间周期内的聚集事实值或状态度量\n    .累计快照事实表:覆盖一个事务从开始到结束之间所有的关键事件,覆盖事务的整个生命周期,通常有多个日期字段来记录关键事件时间点,用于追踪某个业务的全生命周期及状态转换\n.粒度:指数据仓库的数据单位中保存数据的细化或综合程度的级别;\n.度量:业务流程节点上的一个数值,是绝对的定量值;\n.指标:表示某种相对程度的值,是两个或更多度量计算得出相对的定量值\n")])])]),e("h3",{attrs:{id:"数据中台"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据中台"}},[a._v("#")]),a._v(" 数据中台")]),a._v(" "),e("p",[e("strong",[a._v("数据中台|数仓区别")]),a._v(":数仓是支持管理决策和业务分析,数据中台则是将数据服务化后提供给业务系统;数据中台不断地将数据进行资产化、价值化并应用到业务,是一套把数据变成资产并服务业务的机制")]),a._v(" "),e("h3",{attrs:{id:"数据湖"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据湖"}},[a._v("#")]),a._v(" 数据湖")]),a._v(" "),e("p",[e("strong",[a._v("数据湖")]),a._v("本质上是一个中心化的、一体化的存储技术,并且追求技术架构的统一化(如流批一体,服务分析一体化).特点:保真性、灵活性、可管理、可追溯、丰富的计算引擎、多模态存储引擎:")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("①Hudi_uber:在hdfs上提供了更新数据和删除数据的能力以及消费变化数据的能力;使用列式文件格式（Parquet）和行式文件格式（Avro）混合的方式来存储数据.使用列式格式存放Base数据,同时使用行式格式存放增量数据.最新写入的增量数据存放至行式文件中,根据可配置的策略执行操作合并增量数据至列式文件中.表模型:Copy On Write;Merge On Read\n\n②Iceberg_netflix:抽象出table format中间层,独立于上层的计算引擎(如Spark和Flink)和查询引擎(如Hive和Presto),和下层的文件格式(如Parquet,ORC和Avro)相互解耦\n\n③DeltaLake_databricks:为解决云存储中很难实现ACID事务和高性能的问题,思想是使用在云对象存储中的预写日志,以ACID的方式来管理维护Delta表中的信息        \n\n3个引擎的初衷场景:Hudi为了incremental的upserts,Iceberg定位于⾼性能的分析与可靠的数据管理,Delta定位于流批⼀体的数据存储.\n")])])]),e("p",[e("strong",[a._v("湖仓一体")]),a._v(":直接在用于数据湖的低成本存储上实现与数据仓库中类似的数据结构和数据管理功能.避免传统的数据湖、数据仓库之间的数据移动,将原始数据、加工清洗数据、模型化数据，共同存储于一体化的“湖仓”中，既能面向业务实现高并发、精准化、高性能的历史数据、实时数据的查询服务，又能承载分析报表、批处理、数据挖掘等分析型业务")]),a._v(" "),e("p",[e("strong",[a._v("流批一体")]),a._v(":平台层(dp)|api层(table|datastream)|算子层(source|sink connector、unified operator)|插拔组件层(Shuffle组件|调度组件)|资源管理层(k8s);mix表引入了虚拟列和流批标识的能力,在其中一方字段缺失的情况,或者字段的逻辑不是完全一致的情况,通过流批标识,可在代码中显示判断并进行逻辑处理")]),a._v(" "),e("p",[e("strong",[a._v("HSAP")]),a._v(":将简单点查称为数据服务,将复杂查询称为分析,而两者的混合负载就称为HSAP,有4部分:Batch|Analytical交互式分析|Servering高QPS的在线服务|transaction")]),a._v(" "),e("h2",{attrs:{id:"数据管理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据管理"}},[a._v("#")]),a._v(" 数据管理")]),a._v(" "),e("h3",{attrs:{id:"数据管理-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据管理-2"}},[a._v("#")]),a._v(" 数据管理")]),a._v(" "),e("p",[e("strong",[a._v("数据管理")]),a._v(":宏观定目标、中观找方案、微观重任务拆解.数据管理和数据治理的区别,数据管理的整体驱动力是确保组织可以从其数据中获得价值,是总体战略的层面;数据治理聚焦于如何制定有关数据的决策,以及人员和流程在数据方面的行为方式,更多是细节执行层面.数据治理保障数据被管理到,数据管理数据达到既定目标.")]),a._v(" "),e("p",[e("strong",[a._v("数据管理")]),a._v(":dama1定义是规划、控制和提供数据及信息资产的一组业务职能,包括开发、执行和监督有关数据的计划、政策、方案、项目、流程、方法和程序,从而控制、保护、交付和提高数据资产的价值."),e("strong",[a._v("目标")]),a._v(":实现数据资产化、发挥数据资产的价值.")]),a._v(" "),e("p",[e("strong",[a._v("数据资产管理")]),a._v(":定义,紧紧围绕着把数据作为一种资产,基于数据资产的价值、成本、收益开展全生命周期的管理,以体系化的方式实现数据的可用、好用,充分释放数据价值;作用:①全面盘点数据资产②不断提升数据质量③是实现数据互联互通④提高数据获取效率⑤保障数据安全合规⑥数据价值持续释放")]),a._v(" "),e("h3",{attrs:{id:"数据治理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据治理"}},[a._v("#")]),a._v(" 数据治理")]),a._v(" "),e("p",[e("strong",[a._v("数据治理")]),a._v(":①GB定义:数据资源及其应用过程中相关管控活动、绩效和 风险管理的集合②DAMA定义:对数据资产管理行使权力和控制的活动集合③何为数据治理,治为整治,关注数据质量,保障数据稳定性、准确性,合理控制数据的生命周期,降低成本.理为梳理和管理,数据的基本信息、状态、关联关系等,目标是搞清有哪些数据、从哪来到哪去,最终用到什么地方.数据治理是一个从混乱到有序的过程,以服务组织战略目标为基本原则,通过流程制度的制定,以及数据资产的梳理、采集清洗、结构化存储、可视化管理和多维度分析,提升数据资产价值、业务模式创新和经营风险控制的过程.它是涉及企业战略、组织架构、数据标准、管理规范、数据文化、技术工具的综合体.")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("目标:根据策略和最佳实践来正确地管理数据,提升数据价值.\n    狭义是确保数据的质量,可用性,安全性和易用性;\n    广义是解决数据从采集加工/应用分析/销毁全生命周期内的口径、成本、安全、合规和产出问题,提升数据价值\n\n治理4个层面:道术法器.“器”服务于“术”,“术”符合于“法”,“法”根基于“道”,“道法术器”整个体系又在“势”的裹挟下不断演进并驱动“势”的前进和变化。        \n    .战略层面(道|方向):包括数据战略、组织机制、数据文化,重点在于指明哪些决策要制定,由谁来负责,数据战略是顶层的策略.\n    .管理层面(法|路径):包括理现状与定目标、数据治理能力成熟度评估、路线图规划、保障体系建设、技术体系建设、策略执行与监控等.强调数据治理的流程、制度和方法等\n    .执行层面(术|技术):包括建立数据治理各项技术能力,实现对各项数据资源的有效管理和控制,强调数据治理的具体操作和技术,如数据建模、元数据管理、主数据管理、数据质量管理、数据安全治理等\n    .工具层面(器|工具):提升数据治理的效能,工具层面强调对于技术和工具的使用.如主数据管理工具、元数据管理工具、数据质量管理工具、数据安全管理工具、数据交换共享工具等\n\n业务驱动:对业务目标的贡献;降低风险(风险管理|数据安全|数据隐私);优化流程(元数据管理|开发效率|质量提升)数据治理的价值评估,主要包括创造价值和节约成本,即降本增效; \n")])])]),e("p",[e("strong",[a._v("dama2017")]),a._v(":数据管理协会知识体系.11职能:数据架构|数据模型与设计|数据存储与操作|数据安全|数据集成与互操作性|文本与内容管理|参考数据和主数据|数据仓库和商业智能|元数据|数据质量;7个因素:目标和原则|角色和职责|活动|工具|组织和文化|技术|交付成果")]),a._v(" "),e("p",[e("strong",[a._v("dcmm2018")]),a._v(":数据管理能力成熟度评估.8过程域:组织(数据生存周期|数据战略);制度(数据治理|数据架构);流程(数据标准|数据质量);技术(数据安全|数据应用)")]),a._v(" "),e("p",[e("strong",[a._v("dama治理4阶段")]),a._v(":①数据建模和设计|数据存储和运营|数据安全|数据集成和互操作:组织购买包含数据库功能的应用程序.这意味着组织以此作为数据建模和设计、数据存储和数据安全的起点.要使系统在其数据环境中运行,还需要做数据集成和交互操作方面的工作.②数据架构|元数据|数据质量:一旦他们开始使用应用程序,他们将发现数据质量方面的挑战.但获得更高质量的数据取决于可靠的元数据和一致的数据架构.它们说明了来自不同系统的数据是如何协同工作的.③数据治理|文档和内容管理|参考和主数据管理|数仓和BI:管理数据质量、元数据和架构需要严格地实践数据治理,为数据管理活动提供体系性支持.数据治理还支持战略计划的实施,如文档和内容管理、参考数据管理、主数据管理、数据仓库和商务智能,这些黄金金字塔中的高级应用都会得到充分地支持.④数据分析|数据挖掘:该组织充分利用了良好管理数据的好处,并提高了其分析能力.")]),a._v(" "),e("p",[e("strong",[a._v("思考")]),a._v(":系统缺失业务约束,都是事后治理,结合金融和互联网的经验,需要从事后治理向事先管控转变,从被动治理向主动治理转变,从单纯的治理向治理+服务扩展,从理论向实战落地转变;")]),a._v(" "),e("p",[e("strong",[a._v("业界")]),a._v(":二者是为了解决跨技术栈和平台的数据接入和分析问题,让数据还保留在原来的地方,而不是集中到一个平台或者领域.")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("DataFabric是中心化,以技术为中心,通过技术和流程的改进,以智能化的主动元数据为核心来支撑复杂的数据治理,降低数据的管理和使用的难度,提高数据的价值;\n\nDataMesh是分而治之,聚集于方法论,将数据治理拆分到各业务领域,分别产出业务领域的数据产品,通过组织和治理的方式,让数据的所有权分散,更加贴近业务,提高数据的实际应用价值;\n\n两者都难实现原因:技术难度大、组织改变难、质量问题多;实现路径:高效的数据集成能力、精细的数据治理机制、强大的数据分析能力,将数据转化为有价值的信息和洞察;\n")])])]),e("p",[e("strong",[a._v("治理步骤")]),a._v(":准备:①找症状定目标②理数据看现状③定规则做评估;开展:④看结果找原因⑤抓重点分阶段⑥定路线做计划⑦找核心做保障;保障:⑧管进度保治理⑨做评估搭监控;")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("事前控(分析|约束|诊断)|事中管(监控|告警)|事后治(治理|评估|方法论|工具化);\n\n监控体系:指标监控|度量体系:健康分\n\n评估体系:评估报告.如账单,红黑榜\n")])])]),e("p",[e("strong",[a._v("事故处理")]),a._v(":①预防阶段:降低故障率,如开发规范,架构优化②发现阶段:提升监控率,如指标监控、全流程监控③处理阶段:提升处理率,降级策略、优化流程④总结阶段:降低重复率,多做复盘")]),a._v(" "),e("p",[e("strong",[a._v("ant操作")]),a._v(":一套组织体系(组织建设|制度保障)、一套治理方法论(稳定|质量|规范|安全|成本)、一个平台工具支撑&运营(数据研发平台|监控告警平台|数据质量平台)")]),a._v(" "),e("p",[e("strong",[a._v("ant核心步骤")]),a._v(":①成立治理组织②平台能力建设,事前:通过数据研发平台融合治理流程,包含架构约束、项目管控、发布管控;事中:监控告警平台,dqc、基线、实时告警、实时拦截;事后:数据治理平台,治理数字运营,治理画像、成本账单、红黑榜、健康分③技术升级:存储,模型优化分级存储和裁剪,优化回收站,提供存储利用率;计算:一读多写,减少读数据资源消耗;临时表占比超5成,缩短表生命周期设置,自动清理垃圾表")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("平台能力建设:通过基础元数据,沉淀治理数字画像,驱动识别引擎、风险处置、数据管控的能力建设,打造治理融于流程、治理数字运营的平台,在事前、事中、事后进行全方位,全生命周期的数据治理,产出可持续管控的精品资产,同时保障数据不出事、管得住、信得过  \n")])])]),e("p",[e("strong",[a._v("ant案例")]),a._v(":复兴之战,进行设备促活和挽回 发货|激活|开机|活跃|维保|回收|报废;事前:分析评估,组织+流程+来源+埋点+链路;事中:监控告警、基线;事后:看板+复盘;")]),a._v(" "),e("h3",{attrs:{id:"数据安全"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据安全"}},[a._v("#")]),a._v(" 数据安全")]),a._v(" "),e("p",[e("strong",[a._v("数据安全")]),a._v(":包括安全策略和过程规划,建立和执行,为数据和信息资产提供正确的身份验证、授权、访问和审计;")]),a._v(" "),e("p",[e("strong",[a._v("5A")]),a._v(":认证authentication,授权authorization,访问access,审计audit,资产保护asset protection(保密性,完整性,可用性)")]),a._v(" "),e("p",[e("strong",[a._v("mt安全")]),a._v(":采集|传输|存储|处理|共享|销毁")]),a._v(" "),e("p",[e("strong",[a._v("ant安全")]),a._v(":①生产和采集:客户端|爬虫|采购;进行数据打标,个人|业务|公司②传输和跨境:脱敏和加密鉴权③存储和展示:加密,容灾,恢复,脱敏④加工和使用:权限申请,最小原则⑤开放和披露:授权,审批,报备⑥释放和销毁:保留操作记录")]),a._v(" "),e("p",[e("strong",[a._v("MPC安全多方计算")]),a._v(":secure Mulit-Party Computation.mpc提供了一种安全机制,一组互不信任的各个参与方可用共同计算一个约定函数,而不会泄露除结果外的任何其他数据.")]),a._v(" "),e("p",[e("strong",[a._v("FL联邦学习")]),a._v(":FederatedLearning.理念是数据不动模型动,联邦学习框架成功实现了“数据可用不可见”.用户自身的数据从始至终都停留在用户自己的手机或汽车等终端内,不会出域;同时,训练机器学习模型需要的信息,如梯度会以不同的方式被保护(加密、加噪声或拆分),然后在云端的服务器聚合,从而进行模型训练;此后云端再将更新的模型推送给端内.该交互和迭代过程,服务提供商既能够训练高性能的模型为用户提供服务,同时也能保护好用户的数据隐私.")]),a._v(" "),e("p",[e("strong",[a._v("TEE可信执行环境")]),a._v(":Trust Execution Environment.是一种具有运算和储存功能,能提供安全性和完整性保护的独立处理环境.思想是:在硬件中为敏感数据单独分配一块隔离的内存,所有敏感数据的计算均在该内存中进行,并且除了经过授权的接口外,硬件中的其他部分不能访问这块隔离的内存中的信息.以此来实现敏感数据的隐私计算")]),a._v(" "),e("h2",{attrs:{id:"大数据"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#大数据"}},[a._v("#")]),a._v(" 大数据")]),a._v(" "),e("p",[e("strong",[a._v("大数据")]),a._v(":分布式cap,Consistency一致性|Availability可用性|Partition tolerance分区容忍性")]),a._v(" "),e("p",[e("strong",[a._v("olap")]),a._v(":数据量|性能|灵活性①MPP架构:数据量大和灵活性高,缺点:响应时间没保证,性能不稳定②预计算:牺牲灵活性换性能,秒级响应.缺点:不太灵活③搜索引擎:灵活性换性能,缺点:多表查询性能低")]),a._v(" "),e("p",[e("strong",[a._v("ExactlyOnce")]),a._v(":Source端支持数据Replay,保证数据不丢失,Sink端支持幂等或事务.事务两种的实现方式:预写日志write-ahead-log,WAL和两阶段提交two-phase-commit,2PC")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("WAL:①先把结果数据作为日志(log)状态保存起来②进行检查点保存时,也会将这些结果数据一并做持久化存储③在收到检查点完成的通知时,将所有结果一次性写入外部系统;如果检查点已经成功保存、数据也成功地写入到了外部系统,但最终保存确认信息时出现故障,Flink最终还是会认为没有成功写入.于是发生故障时,不会使用这个检查点,而需要回退到上一个,这样就会导致这批数据的重复写入\n    \n2PC:①当第一条数据到来时或者收到检查点的分界线时,Sink任务都会启动一个事务②之后接收到的所有数据,都通过这个事务写入外部系统,这时由于事务没有提交,所以数据尽管写入了外部系统,但是不可用,是“预提交”的状态③当Sink任务收到JobManager发来检查点完成的通知时,正式提交事务,写入的结果可用了\n\nkafka:幂等+事务.幂等producer保证发送单个分区的消息只会发送一次,不会出现重复消息;事务保证原子性地写入到多个分区        \n\nflink:Flink和Kafka连接时,怎样保证端到端的exactly-once状态一致性:\n    ①Flink内部:通过检查点机制保证状态和处理结果的exactly-once语义\n    ②输入端:Kafka可以对数据进行持久化保存,并可以重置偏移量.在Source任务中将当前读取的偏移量保存为算子状态,写入到检查点中;当发生故障时,从检查点中读取恢复状态,并由连接器Consumer向Kafka重新提交偏移量,就可以重新消费数据、保证结果的一致性\n    ③输出端:两阶段提交,写入Kafka的过程实际上是一个两段式的提交:处理结果,写入Kafka是基于事务的预提交;等到检查点保存完毕,才会提交事务进行正式提交.如果中间出现故障,事务进行回滚,预提交就会被放弃;恢复状态之后,也只能恢复所有已经确认提交的操作\n\nsparkStreaming:Direct方式手动操作(手动维护偏移量;处理完数据后再进行提交偏移量操作)\n")])])]),e("p",[e("strong",[a._v("容错")]),a._v(":storm是RecordsACK机制;SparkStreaming是WAL及RDD血统机制;flink是基于Chandy-Lamport分布式快照checkpoint机制,确定当前流式计算所处的状态,包括处理记录和算子状态,然后生成该状态的一致性快照,并将快照存储在持久存储中.")]),a._v(" "),e("p",[e("strong",[a._v("反压")]),a._v(":数据管道中某个节点成为瓶颈,处理速率小于上游发送数据的速率,需要对上游进行限速.")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("strom:从源头降速.是通过zookeeper来决定的,当strom感受到处理不过来时,就会像zookeeper增加一个znode,然后strom发现了这个znode,对应的上游数据就会阻塞,不会发送数据\n\nspark:Receiver模式限制每个receiver每秒可以接受的数据;Direct模式来限制每个分区每次所能接受的最大记录数\n\nflink:逐级反压.通过webUI中BackPressure界面锁定反压算子(subTask的ratio(计算缓冲区阻塞线程数与总线程数的比值)为1和status为high),具体反压是由于当前Task自身处理速度慢还是由于下游Task处理慢导致的,需要通过metric监控判断,可能导致数据延迟或CheckPoint异常,会影响两项指标:checkpoint时长和state大小\n    \n    思路:①并行度优先级设置(算子层面>环境层面>客户端层面>系统层面)②Source并行度:数据源端是Kafka,设置为Kafka对应Topic的分区数③Transform并行度:Keyby之前的算子并行度可以和source保持一致,Keyby之后的算子如果并发较大,建议设置并行度为2的整数次幂,小并发任务的并行度则不一定需要设置成2的整数次幂④Sink端并行度:Sink端要与下游的服务进行交互,并行度还得根据下游的服务抗压能力来设置,如果Sink端的数据量小,并行度可以设置的小一些\n\n    处理:Flink不需要一个特殊的机制来处理背压,因为Flink中的数据传输相当于已经提供了Credit-based应对背压的机制.只有从代码上与资源上去做一些调整①数据倾斜造成的反压,通过数据分组的key预聚合来消除数据倾斜②代码的执行效率问题,阻塞或者性能问题③TaskManager的内存大小导致反压\n\n    案例:流任务出现高反压Source算子消费上游的Kafka具有3个分区,而该flinkSql流任务整体并行度只有1,需要将该任务整体并行度设为3,让一个并行去消费Kafka的分区.设置参数sql.env.parallelism=3;如果仅修改该任务整体并行度的话,会出现Flink资源不足,因为该流任务只有1个TaskManager和1个Slot,最大只能提供1x1=1个并行度,还需设置该任务每个TaskManager包含的Slot数量为3,设置参数Taskmanager.numberOfTaskSlots=3 \n")])])]),e("p",[e("strong",[a._v("Kafka的消息是否会丢失和重复消费")]),a._v(":")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("消息丢失:①生产者丢失:同步模式,确认机制设置为-1(0不需要反馈信息,1写入leader成功,-1所有备份块写入成功),即让消息写入Leader和Follower之后再确认消息发送成功;异步模式,通过buffer进行控制数据的发送,如果buffer满了数据还没有发送出去,如果设置的是立即清理模式,风险很大,一定要设置为阻塞模式.为防止缓冲区满,可以在配置文件设置不限制阻塞超时时间,当缓冲区满时让生产者一直处于阻塞状态②消费者丢失:通过offset提交来保证数据的不丢失,kafka自己记录了每次消费的offset数值,下次继续消费的时候,接着上次的offset进行消费即可.\n\n消息重复:根本原因是已经消费数据offset没提交①生产者重复:ack机制(值取-1)+幂等性(partition内)+事务(事务状态)②消费者重复:将消息唯一标识保存到外部介质中,每次消费时判断是否处理过\n\nKafka消息数据积压,消费能力不足怎么处理:①Kafka消费能力不足,则可以考虑增加Topic的分区数,并且同时提升消费组的消费者数量,消费者数=分区数②下游的数据处理不及时:提高每批次拉取的数量.批次拉取数据过少(拉取数据/处理时间<生产速度),使处理的数据小于生产的数据,也会造成数据积压    \n")])])]),e("p",[e("strong",[a._v("实时处理吞吐量")]),a._v(":①Strom吞吐量小.如水龙头滴水,吞吐量低②SparkStreaming吞吐量大.如河道中开闸关闸,吞吐量高③Flink吞吐量大.如河流远远不断,吞吐量高")]),a._v(" "),e("p",[e("strong",[a._v("实时双流join")]),a._v(":")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("①Left Join:右流数据到达后放入KV缓存,左流数据到达后查询右流的缓存数据,如果能查到则合并输出(关联成功);如果查不到则将左流数据放入延迟队列中,间隔一段时间后再次查右流缓存进行关联(查不到有两种情况:一是右流存在对应的数据但尚未到达;二是右流不存在对应的数据.因此需要等待一段时间,保证第一种情况下尚未到达的右流数据能被关联上).如果超出这个时间窗口仍未关联上,则直接输出,避免无限期等待,超出时间窗口的就认为关联不上,只输出左流的数据,右流为null.这里的右流缓存需要设置过期时间,避免存储无限增长\n\n②Inner Join:左流和右流数据到达后都放入各自KV缓存、并从另一个流的缓存中查询数据,如果能查询到则合并输出(说明另一个流的数据先到达了),如果查询不到就不输出(说明另一个流的数据还未到达或不存在对应数据). 这里左右流的缓存需要设置过期时间,避免存储无限增长.缓存过期时间本质上就是关联时间窗口,超出窗口期的数据会由于缓存已过期而关联不上\n")])])]),e("p",[e("strong",[a._v("redis")]),a._v(":①缓存穿透,访问一个不存在的key,缓存不起作用,请求会穿透到DB,流量大时DB会挂掉;空对象缓存,到期时间不超过5分钟.使用布隆过滤器过滤空值②缓存雪崩,大量的key设置了相同的过期时间,导致在缓存在同一时刻全部失效,所有查询都落在数据库上,引起雪崩;尽量让失效的时间点不分布在同一个时间③缓存击穿,一个热点key,不停的扛着大并发,key失效瞬间,持续的大并发就击破缓存,直接请求数据库,像在屏障中凿了个洞;设置热点key永不过期")]),a._v(" "),e("p",[e("strong",[a._v("doris模型")]),a._v(":①Aggregate模型将表中列分为Key和Value,Key是维度列,Value是指标列②Uniq主键模型可用聚合模型的REPLACE方式替代③Duplicate冗余模型没有主键,没有聚合需求")]),a._v(" "),e("p",[e("strong",[a._v("ClickHouse")]),a._v(":是一个用于OLAP的列式数据库管理系统，它采用了列式存储、数据压缩、多核并行、向量引擎、分布式处理等技术，能到亚秒级别。缺点是不适合大量单条数据的写请求；不适合频繁的数据更新和删除操作，因为变更数据的聚合处理需要时间，短期内可能出现数据不准的现象；不擅长做多张表的关联（尤其是不同数据库引擎的源表之间JOIN）；生态支持弱，不适合多种不同数据源（特别是流式数据源）的接入")]),a._v(" "),e("p",[e("strong",[a._v("MongoDB与Elasticsearch")]),a._v("都属于NoSQL数据库。MongoDB是面向文档的数据库，更适合存储和查询结构化数据，ES是一个全文搜索引擎，则适合存储和搜索大量的文本数据。")]),a._v(" "),e("p",[e("strong",[a._v("KV存储")]),a._v("：美团cellar基于阿里Tair自研；美团squirrel基于redis自研。如果业务的数据量小，对延迟敏感，建议用Squirrel；如果数据量大，对延迟不是特别敏感，建议用成本更低的Cellar。蚂蚁是antKV。")]),a._v(" "),e("h3",{attrs:{id:"mapreduce"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce"}},[a._v("#")]),a._v(" MapReduce")]),a._v(" "),e("p",[e("strong",[a._v("MapReduce")]),a._v(":一种分布式编程模型,采用“分而治之”的思想,将一个大规模数据集分解为多个小规模数据,然后分发给集群中多个节点共同完成计算.可以降低运算复杂度,提高运算效率")]),a._v(" "),e("p",[e("strong",[a._v("map数量")]),a._v("=split数量=文件大小/Math.max(minSize, Math.min(maxSize, blockSize)),splitsize默认是128M,blockSize默认是256M")]),a._v(" "),e("p",[e("strong",[a._v("reducer数量")]),a._v("=min(hive.exec.reducers.max,总输入数据量/hive.exec.reducers.bytes.per.reducer),也可手动设置set mapred.reduce.tasks")]),a._v(" "),e("p",[e("strong",[a._v("Shuffle")]),a._v(":是map阶段产生数据输出到reduce阶段取得数据作为输入之前的一个过程;步骤:分区partition-环形缓冲器memoryBuffer-溢写spill(排序sort-[合并combiner])-归并merge-复制copy-归并merge")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("Collect:将MapTask的结果输出到默认大小为100M的环形缓冲区,保存的是key|value序列化数据,保存前进行Partition分区信息\n\nSpill:当内存中的数据量达到一定的阀值,就会将数据溢写入本地磁盘,数据写入磁盘之前在内存中对数据进行快速排序的操作,若配置combiner,会将有相同分区号和key的数据排序\n\nMapTask阶段Merge:把所有溢出的临时文件进行一次归并排序操作,以确保一个MapTask最终只产生一个整体有序的中间数据文件\n\nCopy:ReduceTask通过RPC向JobTracker询问Map任务是否已经完成,若完成,则开始复制数据,启动Fetcher线程,通过http方式到已经完成MapTask的节点上复制数据,默认会保存在内存的缓冲区,当内存的缓冲区达到一定的阀值,会将数据写到磁盘\n\nReduceTask阶段Merge:在ReduceTask远程复制数据时,会在后台开启两个线程(一个是内存到磁盘的合并,一个是磁盘到磁盘的合并)对内存到本地的数据文件进行归并排序操作\n\nSort：在对数据进行合并时,会进行排序操作,由于MapTask已对数据进行了局部的排序,ReduceTask只需保证Copy的数据的最终整体有效性即可\n")])])]),e("p",[e("strong",[a._v("MapReduce和spark的shuffle相同和差异")]),a._v(":")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("①高层:将mapper的输出进行partition,不同的partition送到不同的reducer.\n②低层:MapReduce是sort-based,Spark默认是hash-based,使用HashMap来对shuffle来的数据进行aggregate,不会对数据进行提前排序.若需求排序,可调用sortByKey\n③实现:MapReduce将处理流程划分出明显的几个阶段:map,spill,merge,shuffle,sort,reduce等.在Spark中,只有不同的stage和一系列的transformation\n④效率:spark把运算的中间数据存放在内存,迭代计算效率更高,mr中间结果需要落地,保存到磁盘\n⑤容错:Spark容错性高,通过RDD来实现,RDD是一组分布式的存储在节点内存中的只读性的数据集,这些集合是弹性的,某部分出错,可以通过数据集的血缘关系来实现重建,mr的容错只能重新计算\n⑥通用:Spark更通用,提供了transformation和action这两大类的多功能api,另外还有流式处理sparkstreaming模块、图计算等等,mr只提供了map和reduce两种操作\n⑦复杂:Spark框架和生态更为复杂,有RDD,lineage、DAG,stage划分等,spark作业需要根据不同业务场景进行调优以达到性能要求,mr框架及其生态相对较为简单,对性能的要求也较弱  \n")])])]),e("h3",{attrs:{id:"spark"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#spark"}},[a._v("#")]),a._v(" spark")]),a._v(" "),e("p",[e("strong",[a._v("Spark")]),a._v(":提交spark任务为一个app,根据任务里的action算子将app划分为多个job,每个job按照宽依赖划分为多个stage,每个stage按照处理数据不同划分为不同task,运行在executor中;stage的task的数量是输入文件的切片个数来决定的;job任务的task数量是stage数量乘以task数量的总和;stage中task并行度就是executor拥有的cores的数量")]),a._v(" "),e("p",[e("strong",[a._v("窄依赖")]),a._v("是父RDD的一个分区只会被子RDD的一个分区依赖,例如map,flatMap,还有filter,不涉及Shuffle操作;")]),a._v(" "),e("p",[e("strong",[a._v("宽依赖")]),a._v("是父RDD的一个分区会被子RDD的多个分区依赖,涉及Shuffle,例reduceBykey(shuffle前会combine)和groupByKey等.")]),a._v(" "),e("p",[e("strong",[a._v("为什么要设计宽窄依赖")]),a._v(":①窄依赖的多个分区可以并行计算②窄依赖的一个分区的数据如果丢失只需要重新计算对应的分区的数据③对于宽依赖,必须等到上一阶段计算完成才能计算下一阶段")]),a._v(" "),e("p",[e("strong",[a._v("repartition")]),a._v("一定会发生shuffle,"),e("strong",[a._v("coalesce")]),a._v("根据传入的参数来判断是否发生shuffle;增大rdd的partition数量用repartition,会进行shuffle,减少时使用coalesce,不会进行shuffle")]),a._v(" "),e("p",[e("strong",[a._v("cache")]),a._v(":内存,不会截断血缘关系,使用计算过程中的数据缓存;checkpoint:磁盘,截断血缘关系,在ck之前必须没有任何任务提交才会生效,ck过程会额外提交一次任务")]),a._v(" "),e("p",[e("strong",[a._v("receiver模式")]),a._v(":①在executor上会有receiver从kafka接收数据并存储在executor中,在到了batch时间后触发job去处理接收到的数据,1个receiver占用1个core②为了不丢数据需要开启WAL预写日志机制,会将receiver接收的数据备份到第三方系统上③receiver内部使用Kafka的高阶API去消费数据及自动更新offset,无法保证数据被处理一次且仅一次,可能会处理两次.因为Spark和zk之间可能是不同步的")]),a._v(" "),e("p",[e("strong",[a._v("direct模式")]),a._v(":①定期查询kafka中的每个partition的最新的offset,每个批次拉取上次处理的offset和当前查询的offset的范围的数据进行处理②为了不丢数据,无需将数据备份落地,而只需要手动保存offset③内部使用Kafka的低阶API去消费数据,需要手动维护offset,kafka zk上不会自动更新offset.一次且仅一次的事务机制")]),a._v(" "),e("p",[e("strong",[a._v("优化")]),a._v(":①对需要重复计算的rdd才使用cache,同时及时释放掉(unpersist)不再需要使用的RDD②避免使用shuffle运算③合理配置参数Executor/Task/core,合理分配持久化/shuffle的内存占比")]),a._v(" "),e("h3",{attrs:{id:"flink"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#flink"}},[a._v("#")]),a._v(" flink")]),a._v(" "),e("p",[e("strong",[a._v("flink")]),a._v(":四个基石Checkpoint|State|Time|Window(时间time/数据count);无重叠Tumbling(size=interval)|有重叠Sliding(size>interval)|丢失数据(size < interval)")]),a._v(" "),e("p",[e("strong",[a._v("运行流程")]),a._v(":Client接收用户CODE编译成StreamGraph,Clien侧优化成JobGraph(算子的Chain链等);流转到JobManager侧转换成ExcutionGraph,资源申请,启动TM,ExcutionGraph转换成物理执行计划,TM执行")]),a._v(" "),e("p",[e("strong",[a._v("运行角色")]),a._v(":")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("①JobManager:集群中的管理者Master,它是整个集群的协调者,负责接收FlinkJob,协调检查点,Failover故障恢复等,同时管理集群中从节点TaskManager\n②TaskManager:负责执行计算的Worker,在其上执行FlinkJob的一组Task,每个TaskManager负责管理其所在节点上的资源信息,如内存、磁盘、网络,在启动的时候将资源的状态向JobManager汇报\n③Client:程序提交的客户端,Client会对Flink程序进行预处理,并提交到Flink集群中处理,所以Client需要从用户提交的Flink程序配置中获取JobManager的地址,并建立到JobManager的连接,将FlinkJob提交给JobManager\n")])])]),e("p",[e("strong",[a._v("容错")]),a._v(":Flink实现容错主要靠CheckPoint机制和State机制.Checkpoint负责定时制作分布式快照、对程序中的状态进行备份;State用来存储计算过程中的中间状态")]),a._v(" "),e("p",[e("strong",[a._v("Checkpoint")]),a._v(":保证Flink集群在某个算子因为某些原因（如,异常退出）出现故障时,能够将整个应用流图的状态恢复到故障之前的某一状态,保证应用流图状态的一致性.每个需要Checkpoint的应用在启动时,Flink的JobManager会创建一个CheckpointCoordinator,它全权负责本应用的快照制作")]),a._v(" "),e("p",[e("strong",[a._v("Watermark")]),a._v(":处理EventTime窗口计算提出的一种机制,本质上是一种时间戳.如果只根据EventTime决定Window的运行,不能明确数据是否全部到位,但又不能无限期的等待,此时要有个机制来保证一个特定的时间后,必须触发Window进行计算,这个机制就是Watermark.Watermark是用于处理乱序事件的,通常用Watermark机制结合Window来实现,可以理解成一个延迟触发机制")]),a._v(" "),e("p",[e("strong",[a._v("高延时任务处理")]),a._v(":在后台任务管理中,可以看到哪个算子和task出现了反压.最主要的手段是资源调优和算子调优.资源调优是对作业中的Operator的并发数(parallelism)、CPU(core)、堆内存(heap_memory)等参数进行调优;作业参数调优包括并行度的设置,State的设置,checkpoint的设置")]),a._v(" "),e("p",[e("strong",[a._v("反压处理")]),a._v(":内部是基于producer-consumer模型来进行消息传递的,Flink的反压设计也是基于这个模型。使用了高效有界的分布式阻塞队列,就像Java阻塞队列,下游消费者消费变慢,上游就会受到阻塞")]),a._v(" "),e("p",[e("strong",[a._v("window出现数据倾斜")]),a._v(":指的是数据在不同的窗口内堆积的数据量相差过多.本质原因是数据源头发送的数据量速度不同导致的。通过两种方式解决:在数据进入窗口前做预聚合;重新设计窗口聚合的key")]),a._v(" "),e("p",[e("strong",[a._v("Flink与SparkStreaming区别")]),a._v(":Flink是标准的实时处理引擎,基于事件驱动;而SparkStreaming是微批(Micro-Batch)的模型.")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("①架构模型:SparkStreaming在运行时的主要角色包括:Master、Worker、Driver、Executor;Flink在运行时主要包含:Jobmanager、Taskmanager和Slot\n②任务调度:SparkStreaming构建有向无环图DAG,会依次创建DStreamGraph-JobGenerator-JobScheduler;Flink根据代码生成StreamGraph,优化生成JobGraph,提交给JobManager处理,JobManager会根据JobGraph生成ExecutionGraph,JobManager根据ExecutionGraph对Job进行调度\n③时间机制:SparkStreaming支持的时间机制有限,只支持处理时间.Flink支持了流处理程序在时间上的三个定义：处理时间、事件时间、注入时间.同时也支持watermark机制来处理滞后数据\n④容错机制:SparkStreaming的checkpoint,发生故障并重启,仅仅是针对driver的故障恢复做了数据和元数据的checkpoint,可以从上次ck之处恢复,但只能使数据不丢失,可能会重复处理,不能做到ExactlyOnce;flink的checkpoint要复杂了很多,它采用的是轻量级的分布式快照,实现了每个算子的快照,及流动中的数据的快照,使用两阶段提交协议来做到ExactlyOnce \n")])])]),e("h2",{attrs:{id:"性能调优"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#性能调优"}},[a._v("#")]),a._v(" 性能调优")]),a._v(" "),e("h3",{attrs:{id:"hadoop"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hadoop"}},[a._v("#")]),a._v(" hadoop")]),a._v(" "),e("p",[e("strong",[a._v("hadoop")]),a._v(":减少数据的传输量|尽量使用内存|减少磁盘IO次数|增大任务并行数|根据集群及网络情况来调优")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("管理员角度:①硬件选择②操作系统参数调优③JVM参数调优④Hadoop参数调优\n\n用户角度:①应用程序编写规范:设置Combiner,选择合理的Writable类型②作业级别参数调优:规划合理的任务数目(map和reduce数)|增加输入文件副本数|设置失败容忍度|提高作业优先级|设置任务超时时间等③任务级别参数调优:MapTask调优(Read|Map|Collect|Spill|Merge)、ReduceTask调优(shuflle(copy)|merge|sort|reduce|write)\n\n存储HDFS小文件优化:①对小文件进行归档(har),将小文件存储成sequenceFile文件②采用combineFileInputFormat来作为输入③对于大量小文件job,可以启用jvm重用\n\nMapReduce优化:\n    ①数据输入:合并小文件|采用CombineTextInputFormat来作为输入,解决输入端大量小文件\n    ②map阶段:增加缓冲区大小;增加缓冲区的溢写比例;较少对溢写文件的merge次数;10个文件改为一次20个merge|采用combiner提前合并,减少IO\n    ③reduce阶段:合理设置map和reduce数|设置map reduce共存|规避使用reduce|增加每个reduce从map取数的并行度|增大reduce端存储数据内存的大小\n    ④IO传输:采用数据压缩的方式,减少网络IO时间.按照snappy和LZOP压缩编码器|使用SequenceFile二进制文件\n    ⑤参数调优:资源相关参数|容错相关参数\n    ⑥整体:增大MapTask和ReduceTask的内存大小|增大MapTask和ReduceTask的cpu核数|增大每个container的cpu核数和内存大小|调整每个MapTask和ReduceTask的重试次数\n\n数据倾斜:解决思路包含数据角度(预处理,数据过滤,模型设计)、业务角度、程序层面(mr|sql|spark算子)、调参层面(利用spark和hive自带的参数来优化)四种.\n")])])]),e("h3",{attrs:{id:"hive"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#hive"}},[a._v("#")]),a._v(" hive")]),a._v(" "),e("p",[e("strong",[a._v("hive")]),a._v(":参数调优|压缩存储|sql优化")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("参数调优:Fetch抓取|本地模式|并行执行|jvm重用|推测执行\n\n压缩存储:行存储TextFile|SequenceFiles;列存储RCFile|ORCFile|Parquet;压缩的选择:压缩比率|压缩解压缩速度|是否支持Split(常用的是snappy压缩方法)\n\nSQL优化:join|where|count distinct|union|group by|等\n\n数据倾斜:①sql:count distinct|group by|join(map join|skewjoin)②参数:开启map端aggr|开启数据倾斜时负载均衡(hive.groupby.skewindata=true)\n")])])]),e("h3",{attrs:{id:"spark-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#spark-2"}},[a._v("#")]),a._v(" spark")]),a._v(" "),e("p",[e("strong",[a._v("spark")]),a._v(":开发过程中的优化|运行前的资源参数设置调优|运行中的数据倾斜的解决方案")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("开发调优:①避免创建重复RDD②复用RDD③对多次使用的RDD持久化④避免shuffle算子⑤用mapside预聚合shuffle操作⑥使用高性能算子⑦广播大变量⑧Kryo优化序列化性能⑨优化数据结构\n\n数据倾斜:①Hive预处理②过滤少数导致倾斜的key③提高shuffle操作的并行度④两阶段聚合⑤将reducejoin转为mapjoin⑥采样倾斜key并分拆join操作⑦使用随机前缀和扩容RDD进行join\n\nShuffle调优:①HashShuffleManager:未优化的HashShuffle会产生大量的中间磁盘文件影响性能;优化后的HashShuffle,就不再是每个mapTask为下游的每个reduceTask生成一个磁盘文件,而是一个executor为一个reduceTask生成一个磁盘文件②SortShuffleManager:普通运行机制,溢写到磁盘之前,先按照数据的key进行排序,排序后分批次写入磁盘,默认每批次1w条数据;bypass运行机制,mapTask数据溢写到磁盘之前不会对数据进行排序\n\nSpark与MapReduce相比,Spark运行效率更高原因:①基于内存计算,减少低效的磁盘交互②基于DAG高效的调度算法③容错机制Linage\n")])])]),e("h3",{attrs:{id:"flink-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#flink-2"}},[a._v("#")]),a._v(" flink")]),a._v(" "),e("p",[e("strong",[a._v("flink")]),a._v(":如何处理生产环境中的数据倾斜问题")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("表现:任务节点频繁出现反压,增加并行度也不能解决问题;部分节点出现OOM异常,是因为大量的数据集中在某个节点上,导致该节点内存被爆,任务失败重启\n\n原因:业务上有严重的数据热点.技术上大量使用了KeyBy、GroupBy等操作,错误的使用了分组Key,人为产生数据热点\n\n定位反压:WebUI自带的反压监控（直接方式）、Flink Task Metrics（间接方式）.通过监控反压的信息，可以获取到数据处理瓶颈的Subtask;定位数据倾斜:WebUI自带Subtask接收和发送的数据量。当Subtasks 之间处理的数据量有较大的差距，则该Subtask出现数据倾斜。\n\n思路:业务上要尽量避免热点key的设计;技术上,打散原来的热点key,避免直接聚合;数据源source消费不均匀时,通过调整Flink并行度，解决数据源消费不均匀或者数据源反压的情况;两阶段聚合解决 KeyBy（加盐局部聚合+去盐全局聚合）\n")])])]),e("h2",{attrs:{id:"数据结构和算法"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据结构和算法"}},[a._v("#")]),a._v(" 数据结构和算法")]),a._v(" "),e("p",[e("strong",[a._v("数据结构")]),a._v(":①表:线性表(队列|栈|数组|链表)|哈希表②树:二叉树(平衡二叉查找树(avl树|红黑树)|完全二叉树);多路查找树(B-|B+树|2-3树|2-3-4树);堆(大|小跟堆)③图(邻接矩阵|邻接表)")]),a._v(" "),e("p",[e("strong",[a._v("list|set|map")]),a._v(":List中数据是有序的,值允许重复;Map中数据是无序的,键不允许重复,值允许重复;Set中数据是无顺序的,并且不允许重复,元素在集合中的位置是由元素的hashcode决定,即位置是固定的;")]),a._v(" "),e("p",[e("strong",[a._v("监督学习")]),a._v("的核心是回归和分类,其任务是学习一个模型,使模型能够对任意给定的输入,对其相应的输出做出一个好的预测.即:利用训练数据集学习一个模型,再用模型对测试样本集进行预测.本质是在结果可验证的情况下,建立输入参数和输出参数之间的关系,这种关系被称为假设;机器学习方法:线性回归算法、BP神经网络算法、决策树、支持向量机、KNN等;集成学习:随机森林、梯度提升决策数、adaboost、XGboost;多层监督机:dnn")]),a._v(" "),e("p",[e("strong",[a._v("无监督学习")]),a._v("的核心是聚类和降维,直接对数据进行建模.没有给定事先标记过的训练范例,所用的数据没有属性或标签这一概念.事先不知道输入数据对应的输出结果是什么.自动对输入的资料进行分类或分群,以寻找数据的模型和规律;KNN、谱聚类、密度估计、层次聚类、K-Means算法(K均值算法)、DBSCAN算法;生产模型:贝叶斯网络;判别模型:mlp")]),a._v(" "),e("p",[e("strong",[a._v("算法思想")]),a._v(":穷举、回溯、递归、贪心、分治、动态规划、分支界限")]),a._v(" "),e("p",[e("strong",[a._v("排序")]),a._v(":内部排序(⽐较排序(插⼊(直接插⼊|希尔)|选择(直接选择|堆)|交换(冒泡|快速排序)|归并排序)|⾮⽐较排序(也叫线性排序,计数|桶|基数))外部排序")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("冒泡:稳定,平均O(n²);⽐较相邻的元素,如果第⼀个⽐第⼆个⼤就进⾏交换,重复以上\n\n快排:对冒泡排序的改进,不稳定,平均O(nlogn);选择⼀个基准元素,通过⼀趟排序将要排序的数据分割成的两部分,⼀部分<=基准元素,⼀部分>=基准元素,再递归对这两部分数据进⾏快速排序\n\n归并:稳定,平均O(nlogn);我们先把数组从中间分成前后两部分,然后对前后两部分分别排序,再将排好序的两部分合并在一起,这样整个数组就都有序了\n")])])]),e("p",[e("strong",[a._v("md5")]),a._v("不可逆128位|base64可逆8bit)|sha不可逆,SHA1的全称是Secure Hash Algorithm,SHA1基于MD5,加密数据长度更长|rsa公钥加密,私钥解密|aes对称密钥加密")]),a._v(" "),e("h2",{attrs:{id:"数据库"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据库"}},[a._v("#")]),a._v(" 数据库")]),a._v(" "),e("p",[e("strong",[a._v("索引失效")]),a._v(":①不在索引列上做任何操作,会索引失效全表扫描②不能用索引范围条件右边列③尽量使用覆盖索引,减少select*④mysql在使用不等于的时候无法使用索引会导致全表扫描⑤is null,is not null无法使用索引⑥like以通配符开头(’%abc’)mysql索引失效会变成全表扫描的操作⑦复合索引:例如索引是(a,b,c);支持a|a,b|a,b,c3种组合进行查找,不支持b,c查找")]),a._v(" "),e("p",[e("strong",[a._v("事务acid")]),a._v(":原子性,一致性,隔离性,持久性")]),a._v(" "),e("p",[e("strong",[a._v("事务并发问题")]),a._v(":不可重复读重点在于update和delete,幻读的重点在于insert.所以不可重复读和幻读的区别就在于如何通过锁机制来解决他们产生的问题.")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("Dirty Read 脏读:一个事务读到了另一个未提交的事务写的数据\n\nNon-Repeatable Read 不可重复读:一个事务中两次读同一行数据,可是这两次读到的数据不一样\n\nPhantom Read 幻读:一个事务中两次查询,但第二次查询比第一次查询多了或少了几行或几列数据\n")])])]),e("p",[e("strong",[a._v("sql")]),a._v(":")]),a._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",[e("code",[a._v("行转列:lateral view explode(split(amt,',')) a as amt;\n列转行:concat_ws(',',collect_list(amt));GROUPING SETS|WITH CUBE|WITH ROLLUP;LEAD(col,n-1,null)OVER()    \n")])])]),e("h2",{attrs:{id:"其他"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#其他"}},[a._v("#")]),a._v(" 其他")]),a._v(" "),e("p",[e("strong",[a._v("jvm内存分区及作用")]),a._v(":①堆和方法区是所有线程共享的资源,其中堆是进程中最大的一块内存,主要用于存放新创建的对象(所有对象都在这里分配内存);②方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后代码等数据③虚拟机栈:Java方法在执行时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息.从方法调用直至执行完成,就对应着一个栈帧在Java虚拟机栈中入栈和出栈的过程④本地方法栈:和虚拟机栈所发挥的作用非常相似,区别是:虚拟机栈为虚拟机执行Java方法服务,而本地方法栈则为虚拟机使用到的Native方法服务⑤程序计数器私有主要是为了线程切换后能恢复到正确的执行位置")]),a._v(" "),e("p",[e("strong",[a._v("URL访问网站过程")]),a._v(":①通过域名找到IP,如果缓存里没有就要请求DNS服务器②得到IP后开始与目的主机进行三次握手来建立TCP连接③连接建立后进行HTTP访问,传输并获取网页内容④传输完后与目的主机四次挥手来断开TCP连接")]),a._v(" "),e("p",[e("strong",[a._v("3次握手")]),a._v(":作用是为了确认双方的接收与发送能力是否正常.①第一次:客户端给服务器发送一个SYN报文.客户端发送网络包,服务端收到了.服务端得出结论:客户端发送能力、服务端接收能力是正常的②第二次:服务器收到SYN报文之后,会应答一个SYN+ACK报文.服务端发包,客户端收到了.客户端得出结论:服务端接收、发送能力,客户端接收、发送能力是正常的.但此时服务器并不能确认客户端的接收能力是否正常③第三次:客户端收到SYN+ACK报文之后,会回应一个ACK报文.客户端发包,服务端收到了.服务端得出结论:客户端的接收、发送能力正常,服务器的发送、接收能力也正常.第一次、第二次握手不可以携带数据,而第三次握手是可以携带数据的.")]),a._v(" "),e("p",[e("strong",[a._v("为什么连接是三次握手,关闭却是四次握手")]),a._v(":因为当Server端收到Client端的SYN连接请求报文后,可以直接发送SYN+ACK报文.其中ACK报文是用来应答的,SYN报文是用来同步的.但是关闭连接时,当Server端收到FIN报文时,可能并不会立即关闭SOCKET,所以只能先回复一个ACK报文,告诉Client端,你发的FIN报文我收到了.等到Server端所有的报文都发送完了,才能发送FIN报文,不能一起发送,故需要四步握手")])])}),[],!1,null,null,null);e.default=r.exports}}]);