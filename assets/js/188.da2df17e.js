(window.webpackJsonp=window.webpackJsonp||[]).push([[188],{519:function(a,v,e){"use strict";e.r(v);var t=e(4),_=Object(t.a)({},(function(){var a=this,v=a._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[v("h1",{attrs:{id:"大数据处理-overview"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#大数据处理-overview"}},[a._v("#")]),a._v(" 大数据处理 - Overview")]),a._v(" "),v("blockquote",[v("p",[a._v("本文主要介绍大数据处理的一些思路。")])]),a._v(" "),v("h2",{attrs:{id:"何谓海量数据处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#何谓海量数据处理"}},[a._v("#")]),a._v(" 何谓海量数据处理?")]),a._v(" "),v("p",[a._v("所谓海量数据处理，无非就是基于海量数据上的存储、处理、操作。何谓海量，就是数据量太大，所以导致要么是无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。")]),a._v(" "),v("p",[a._v("那解决办法呢?")]),a._v(" "),v("ul",[v("li",[v("code",[a._v("针对时间")]),a._v(": 我们可以采用巧妙的算法搭配合适的数据结构，如Bloom filter/Hash/bit-map/堆/数据库或倒排索引/trie树；")]),a._v(" "),v("li",[v("code",[a._v("针对空间")]),a._v(": 无非就一个办法: 大而化小，分而治之(hash映射);")]),a._v(" "),v("li",[v("code",[a._v("集群|分布式")]),a._v(": 通俗点来讲，单机就是处理装载数据的机器有限(只要考虑cpu，内存，硬盘的数据交互); 而集群适合分布式处理，并行计算(更多考虑节点和节点间的数据交互)。")])]),a._v(" "),v("h2",{attrs:{id:"具体思路"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#具体思路"}},[a._v("#")]),a._v(" 具体思路")]),a._v(" "),v("ul",[v("li",[v("a",{attrs:{href:"/pages/alg-domain-bigdata-devide-hash"}},[a._v("大数据处理 - 分治/hash/排序")]),a._v(" "),v("ul",[v("li",[a._v("就是先映射，而后统计，最后排序:")]),a._v(" "),v("li",[v("code",[a._v("分而治之/hash映射")]),a._v(": 针对数据太大，内存受限，只能是: 把大文件化成(取模映射)小文件，即16字方针: 大而化小，各个击破，缩小规模，逐个解决")]),a._v(" "),v("li",[v("code",[a._v("hash_map统计")]),a._v(": 当大文件转化了小文件，那么我们便可以采用常规的hash_map(ip，value)来进行频率统计。")]),a._v(" "),v("li",[v("code",[a._v("堆/快速排序")]),a._v(": 统计完了之后，便进行排序(可采取堆排序)，得到次数最多的IP。")])])]),a._v(" "),v("li",[v("a",{attrs:{href:"/pages/alg-domain-bigdata-bloom-filter"}},[a._v("大数据处理 - Bitmap & Bloom Filter")]),a._v(" "),v("ul",[v("li",[a._v("布隆过滤器有着广泛的应用，对于大量数据的“存不存在”的问题在空间上有明显优势，但是在判断存不存在是有一定的错误率(false positive)，也就是说，有可能把不属于这个集合的元素误认为属于这个集合(False Positive)，但不会把属于这个集合的元素误认为不属于这个集合(False Negative)")])])]),a._v(" "),v("li",[v("a",{attrs:{href:"/pages/alg-domain-bigdata-bucket"}},[a._v("大数据处理 - 双层桶划分")]),a._v(" "),v("ul",[v("li",[a._v("其实本质上还是分而治之的思想，重在“分”的技巧上！"),v("code",[a._v("适用范围")]),a._v(": 第k大，中位数，不重复或重复的数字；"),v("code",[a._v("基本原理及要点")]),a._v(": 因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。")])])]),a._v(" "),v("li",[v("a",{attrs:{href:"/pages/alg-domain-bigdata-db-index"}},[a._v("大数据处理 - Trie树/数据库/倒排索引")]),a._v(" "),v("ul",[v("li",[v("code",[a._v("适用范围")]),a._v(": 数据量大，重复多，但是数据种类小可以放入内存；"),v("code",[a._v("基本原理及要点")]),a._v(": 实现方式，节点孩子的表示方式；"),v("code",[a._v("扩展")]),a._v(": 压缩实现")])])]),a._v(" "),v("li",[v("a",{attrs:{href:"/pages/alg-domain-bigdata-outsort"}},[a._v("大数据处理 - 外排序")]),a._v(" "),v("ul",[v("li",[v("code",[a._v("适用范围")]),a._v(": 大数据的排序，去重；"),v("code",[a._v("基本原理及要点")]),a._v(": 外排序的归并方法，置换选择败者树原理，最优归并树")])])]),a._v(" "),v("li",[v("a",{attrs:{href:"/pages/alg-domain-bigdata-map-reduce"}},[a._v("大数据处理 - Map & Reduce")]),a._v(" "),v("ul",[v("li",[a._v("MapReduce是一种计算模型，简单的说就是将大批量的工作(数据)分解(MAP)执行，然后再将结果合并成最终结果(REDUCE)。这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，减少整个操作的时间。但如果你要我再通俗点介绍，那么，说白了，Mapreduce的原理就是一个归并排序")])])])]),a._v(" "),v("h2",{attrs:{id:"参考文章"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[a._v("#")]),a._v(" 参考文章")]),a._v(" "),v("ul",[v("li",[a._v("https://blog.csdn.net/v_july_v/article/category/1106578")]),a._v(" "),v("li",[a._v("https://blog.csdn.net/v_JULY_v/article/details/6279498")]),a._v(" "),v("li",[a._v("https://blog.csdn.net/v_JULY_v/article/details/7382693")]),a._v(" "),v("li",[a._v("https://blog.csdn.net/meng984611383/article/details/80060096")])])])}),[],!1,null,null,null);v.default=_.exports}}]);